results <- rbind(results, data.frame(alpha = alpha,
lambda.min = cv_fit$lambda.min,
mse = min(cv_fit$cvm)))
}
best_alpha <- results[which.min(results$mse), "alpha"]
best_lambda <- results[which.min(results$mse), "lambda.min"]
final_elastic_net_model <- glmnet(X.training, Y.training, alpha = best_alpha, lambda = best_lambda)
coef(final_elastic_net_model)
summary(final_elastic_net_model)
final_elastic_net_model_training_predictions <- predict(final_elastic_net_model, newx = X.training, type = "response")
final_elastic_net_model_training_predictions <- as.vector(final_elastic_net_model_training_predictions)
elastic_training_MSE <- mean((final_elastic_net_model_training_predictions-Y.training)^2)
elastic_net_cve <- min(results$mse)
##test performance
elastic_freq_predictions <- predict(final_elastic_net_model, newx = x.test, type = "response")
elastic_freq_predictions <- as.vector(elastic_freq_predictions)
elastic_test_mse <- mean((elastic_freq_predictions - y.test)^2)
elastic_test_mse
ridge_test_mse
lasso_test_mse
training_lasso_MSE
stepwise_freq_model_test_MSE
predicted.values <- predict(freq_lasso_model, newdata = freq_pred_data, type = "response")
model.matrix(~., data = freq_pred_data)
predicted.values <- predict(freq_lasso_model, newdata = model.matrix(~., data = freq_pred_data)[,-1], type = "response")
predicted.values <- predict(freq_lasso_model, newx = model.matrix(~., data = freq_pred_data)[,-1], type = "response")
model.matrix(~., data = freq_pred_data)[,-1]
ncol(model.matrix(~., data = freq_pred_data)[,-1])
ncol(X.training)
colnames(X.training)[which(!(colnames(X.training) %in% model.matrix(~., data = freq_pred_data)[,-1]))]
colnames(X.training) %in% model.matrix(~., data = freq_pred_data)[,-1])
colnames(X.training) %in% model.matrix(~., data = freq_pred_data)[,-1]
colnames(X.training)
colnames(model.matrix(~., data = freq_pred_data)[,-1])
X.training <- model.matrix(claim_freq~., data = freq_training_val)[,-1]
Y.training <- freq_training_val$claim_freq
freq_lasso_model <- cv.glmnet(X.training, Y.training, alpha = 1)
lasso_optimal_lambda <- freq_lasso_model$lambda.min
final_freq_lasso_model <- glmnet(X.training, Y.training, lambda = lasso_optimal_lambda, alpha = 1)
coef(final_freq_lasso_model)
lasso_freq_predictions_training <- predict(final_freq_lasso_model, newx = X.training, type = "response")
lasso_freq_predictions_training <- as.vector(lasso_freq_predictions_training)
training_lasso_MSE <- mean((lasso_freq_predictions_training-Y.training)^2)
#Test Performance
x.test <- model.matrix(claim_freq~., data = freq_test)
y.test <- freq_test$claim_freq
lasso_prediction_freq <- predict(final_freq_lasso_model, newx = x.test, type = "response")
X.training <- model.matrix(claim_freq~., data = freq_training_val)[,-1]
Y.training <- freq_training_val$claim_freq
freq_lasso_model <- cv.glmnet(X.training, Y.training, alpha = 1)
lasso_optimal_lambda <- freq_lasso_model$lambda.min
final_freq_lasso_model <- glmnet(X.training, Y.training, lambda = lasso_optimal_lambda, alpha = 1)
coef(final_freq_lasso_model)
lasso_freq_predictions_training <- predict(final_freq_lasso_model, newx = X.training, type = "response")
lasso_freq_predictions_training <- as.vector(lasso_freq_predictions_training)
training_lasso_MSE <- mean((lasso_freq_predictions_training-Y.training)^2)
#Test Performance
x.test <- model.matrix(claim_freq~., data = freq_test)[,-1]
y.test <- freq_test$claim_freq
lasso_prediction_freq <- predict(final_freq_lasso_model, newx = x.test, type = "response")
lasso_prediction_freq <- as.vector(lasso_prediction_freq)
lasso_test_mse <- mean((lasso_prediction_freq - y.test)^2)
###Ridge###
freq_ridge_model <- cv.glmnet(X.training, Y.training, alpha = 0)
ridge_optimal_lambda <- freq_ridge_model$lambda.min
final_ridge_model_freq <- glmnet(X.training, Y.training, lambda = ridge_optimal_lambda, alpha = 0)
ridge_freq_predictions_training <- predict(final_ridge_model_freq, newx = X.training, type = "response")
ridge_freq_predictions_training <- as.vector(ridge_freq_predictions_training)
training_ridge_MSE <- mean((ridge_freq_predictions_training-Y.training)^2)
coef(final_ridge_model_freq)
#test performance#
ridge_freq_predictions <- predict(final_ridge_model_freq, newx = x.test, type = "response")
ridge_freq_predictions <- as.vector(ridge_freq_predictions)
ridge_test_mse <- mean((ridge_freq_predictions - y.test)^2)
###Elastic Net###
set.seed(12313)
alpha_values <- seq(0, 1, by = 0.1)
results <- data.frame(alpha = numeric(), lambda.min = numeric(), mse = numeric())
for (alpha in alpha_values) {
cv_fit <- cv.glmnet(X.training, Y.training, alpha = alpha, nfolds = 10)
results <- rbind(results, data.frame(alpha = alpha,
lambda.min = cv_fit$lambda.min,
mse = min(cv_fit$cvm)))
}
best_alpha <- results[which.min(results$mse), "alpha"]
best_lambda <- results[which.min(results$mse), "lambda.min"]
final_elastic_net_model <- glmnet(X.training, Y.training, alpha = best_alpha, lambda = best_lambda)
coef(final_elastic_net_model)
summary(final_elastic_net_model)
final_elastic_net_model_training_predictions <- predict(final_elastic_net_model, newx = X.training, type = "response")
final_elastic_net_model_training_predictions <- as.vector(final_elastic_net_model_training_predictions)
elastic_training_MSE <- mean((final_elastic_net_model_training_predictions-Y.training)^2)
elastic_net_cve <- min(results$mse)
##test performance
elastic_freq_predictions <- predict(final_elastic_net_model, newx = x.test, type = "response")
elastic_freq_predictions <- as.vector(elastic_freq_predictions)
elastic_test_mse <- mean((elastic_freq_predictions - y.test)^2)
elastic_test_mse
ridge_test_mse
lasso_test_mse
predicted.values <- predict(freq_lasso_model, newx = model.matrix(~., data = freq_pred_data)[,-1], type = "response")
predicted.values
predicted.values <- predict(freq_lasso_model, newx = model.matrix(~., data = freq_pred_data)[,-1])
predicted.values
min(predicted.values)
max(predicted.values)
ggplot(mse_df, aes(x = reorder(Variable, MSE), y = MSE)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +  # Flips the axes for better readability
labs(title = "Variable Importance (Mean Decrease MSE)",
x = "Variables",
y = "Mean Decrease MSE") +
theme_minimal()
summary(final_freq_lasso_model)
final_freq_lasso_model$dev.ratio
alpha_values <- seq(0, 1, by = 0.1)
results <- data.frame(alpha = numeric(), lambda.min = numeric(), mse = numeric())
for (alpha in alpha_values) {
cv_fit <- cv.glmnet(X.training, Y.training, alpha = alpha, nfolds = 10)
results <- rbind(results, data.frame(alpha = alpha,
lambda.min = cv_fit$lambda.min,
mse = min(cv_fit$cvm)))
}
best_alpha <- results[which.min(results$mse), "alpha"]
best_lambda <- results[which.min(results$mse), "lambda.min"]
final_elastic_net_model <- glmnet(X.training, Y.training, alpha = best_alpha, lambda = best_lambda)
final_elastic_net_model_training_predictions <- predict(final_elastic_net_model, newx = X.training, type = "response")
final_elastic_net_model_training_predictions <- as.vector(final_elastic_net_model_training_predictions)
elastic_training_MSE <- mean((final_elastic_net_model_training_predictions-Y.training)^2)
elastic_training_MSE
training_lasso_MSE
elastic_test_mse
training_lasso_MSE
load("C:/Users/User/OneDrive/Documents/GitHub/ACTL4305/modelling/.RData")
# Load necessary libraries
library(stats)
library(dplyr)
library(gamlr)
library(tweedie)
library(mgcv)
library(statmod)
library(forcats)
library(tidyr)
library(randomForest)
library(glmnet)
library(caret)
library(gbm)
freq_rf <- randomForest(claim_freq ~., data = freq_training_val, ntree = 100, importance = TRUE)
#Training fit
rf_training_pridictions <- predict(freq_rf, newdata = freq_training_val)
rf_training_pridictions <- as.vector(rf_training_pridictions)
training_mse_rf <- mean((rf_training_pridictions - freq_training_val$claim_freq)^2)
#Variable Importance
importance_values <- importance(freq_rf)
mse_importance <- importance_values[, "%IncMSE"]
mse_df <- data.frame(Variable = rownames(importance_values), MSE = mse_importance)
ggplot(mse_df, aes(x = reorder(Variable, MSE), y = MSE)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +  # Flips the axes for better readability
labs(title = "Variable Importance (Mean Decrease MSE)",
x = "Variables",
y = "Mean Decrease MSE") +
theme_minimal()
frequency.model.data <- frequency.model.data[,-which(colnames(frequency.model.data) %in% additional.var.to.remove)]
-which(colnames(frequency.model.data) %in% additional.var.to.remove)
frequency.model.data
colnames(frequency.model.data) %in% additional.var.to.remove
additional.var.to.remove <- c("qi", "nb_state_num", "size_encoding", "lead_date_day", "UW_Date", "quote_time_group_num", "density", "is_multi_pet_plan_num")
frequency.model.data <- frequency.model.data[,-which(colnames(frequency.model.data) %in% additional.var.to.remove)]
frequency.model.data
set.seed(2131)
freq_training_val_index <- sample(1:nrow(frequency.model.data), 0.7*nrow(frequency.model.data))
freq_training_val <- frequency.model.data[freq_training_val_index, ]
freq_test <- frequency.model.data[-freq_training_val_index, ]
#Assessing Distribution of claim_freq
mean_claim <- mean(frequency.model.data$claim_freq, na.rm = TRUE)
sd_claim <- sd(frequency.model.data$claim_freq, na.rm = TRUE)
ggplot(frequency.model.data, aes(x = claim_freq)) +
geom_density(fill = "lightblue", color = "darkblue", alpha = 0.6) +
stat_function(fun = dnorm, args = list(mean = mean_claim, sd = sd_claim),
color = "red", linetype = "dashed", size = 1) +
labs(title = "Density Plot of Claim Frequency with Normal Curve",
x = "Claim Frequency",
y = "Density") +
theme_minimal() +
xlim(0, 1)
# ==================================================================================================
# GLM - Tweedie
# ==================================================================================================
var_powers <- seq(1, 2, by = 0.1)
mse_results <- numeric(length(var_powers))
train_control <- trainControl(method = "cv", number = 5)
for (i in seq_along(var_powers)) {
current_power <- var_powers[i]
model <- train(
claim_freq ~ ., data = freq_training_val,
method = "glm",
family = tweedie(var.power = current_power, link = "log"),
trControl = train_control,
metric = "RMSE"
)
mse_results[i] <- mean(model$resample$RMSE^2)
}
optimal_var_power <- var_powers[which.min(mse_results)]
optimal_var_power
tweedie_freq_model <- glm(claim_freq ~ ., data = freq_training_val, family = tweedie(var.power = optimal_var_power, link = "log"))
tweedie_freq_model_training_predictions <- pmax(predict(tweedie_freq_model,  newdata = freq_training_val, type = "response"),0)
tweedie_freq_model_training_predictions <- as.vector(tweedie_freq_model_training_predictions)
training_MSE_tweedie <- mean((tweedie_freq_model_training_predictions-freq_training_val$claim_freq)^2)
#Performance on the test data
tweedie_freq_model_prediction <- predict(tweedie_freq_model,  newdata = freq_test, type = "response")
tweedie_freq_model_prediction <- as.vector(tweedie_freq_model_prediction)
test_MSE_tweedie <- mean((tweedie_freq_model_prediction-freq_test$claim_freq)^2)
sdu <- summary(tweedie_freq_model)
tweedie_freq_model$deviance
test_MSE_tweedie
RSS <- sum((freq_training_val$claim_freq - tweedie_freq_model_training_predictions)^2)
SST <- sum(freq_training_val$claim_freq - mean(freq_training_val$claim_freq)^2)
R2 <- 1 - (RSS / SST)
n <- nrow(freq_training_val)
k <- length(coef(tweedie_freq_model)) - 1
R2_adj <- 1 - ((1 - R2) * (n - 1) / (n - k - 1))
freq_glm_test_residuals <- freq_test$claim_freq - pmax(predict(tweedie_freq_model, newdata = freq_test, type = "response"),0)
glm_freq_test_results <- data.frame(test_residuals = freq_glm_test_residuals, Actual_Claim_Freq = freq_test$claim_freq)
ggplot(glm_freq_test_results, aes(x = Actual_Claim_Freq, y = test_residuals)) +
geom_point(color = "blue", alpha = 0.6, size = 2) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(
title = "Tweedie GLM Residuals vs. Claim Frequency",
x = "Actual Claim Frequency",
y = "New Residuals"
) +
theme_minimal(base_size = 15) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title.x = element_text(margin = ggplot2::margin(t = 10)),
axis.title.y = element_text(margin = ggplot2::margin(r = 10))
)
mse_freq_glm <- mean((glm_freq_test_results$test_residuals)^2)
mse_freq_glm
freq_training_val$residuals <- freq_training_val$claim_freq - predict(tweedie_freq_model, newdata = freq_training_val, type = "response")
freq_pred_data <- freq_pred_data[,-additional.var.to.remove]
freq_pred_data <- freq_pred_data[,-which(colnames(freq_pred_data) %in% additional.var.to.remove)]
predicted.values <- predict(tweedie_freq_model, newdata = freq_pred_data)
predicted.values
predicted.values <- predict(tweedie_freq_model, newdata = freq_pred_data, type = "response")
predicted.values
predicted.values <- pmax(predict(tweedie_freq_model, newdata = freq_pred_data, type = "response"),0)
predicted.values
min(predicted.values)
max(predicted.values)
predicted.values.glm <- pmax(predict(tweedie_freq_model, newdata = freq_pred_data, type = "response"),0)
vars.to.remove <- c("exposure_id", "pet_gender", "pet_de_sexed_age", "pet_is_switcher", "nb_address_type_adj", "nb_suburb", "nb_state", "person_dob", "owner_age_years", "nb_breed_type",
"nb_breed_trait", "nb_breed_name_unique", "nb_breed_name_unique_concat", "exposure_id_1", "earned_units", "Total_Earned", "claim_nb", "Total_claim_amount",
"Total_claim_paid", "severity", "frequency", "is_multi_plan", "quote_time_group", "sa2_code", "nb_postcode", "is_multi_pet_plan", "pet_age_year")
frequency.model.data <- combined_data[,-which(colnames(combined_data) %in% vars.to.remove)]
frequency.model.data$qi <- ifelse(frequency.model.data$qi == "Good", 1,
ifelse(frequency.model.data$qi == "Acceptable", 2,
ifelse(frequency.model.data$qi == "Poor", 3, NA)))
frequency.model.data$qi <- as.numeric(frequency.model.data$qi)
frequency.model.data$pet_de_sexed <- ifelse(frequency.model.data$pet_de_sexed == "true", 2, ifelse(frequency.model.data$pet_de_sexed == "false", 1, NA))
frequency.model.data$pet_de_sexed <- as.numeric(frequency.model.data$pet_de_sexed)
frequency.model.data <- frequency.model.data %>%  #Convert all NA's to the mean of the column
mutate_if(is.numeric, ~ ifelse(is.na(.), mean(., na.rm = TRUE), .))
#######TESTING REMOVAL OF PREDICTORS########
additional.var.to.remove <- c("qi", "nb_state_num", "size_encoding", "lead_date_day", "UW_Date", "quote_time_group_num", "density", "is_multi_pet_plan_num")
frequency.model.data <- frequency.model.data[,-which(colnames(frequency.model.data) %in% additional.var.to.remove)]
#Splitting into test and training
set.seed(2131)
freq_training_val_index <- sample(1:nrow(frequency.model.data), 0.7*nrow(frequency.model.data))
freq_training_val <- frequency.model.data[freq_training_val_index, ]
freq_test <- frequency.model.data[-freq_training_val_index, ]
#Assessing Distribution of claim_freq
mean_claim <- mean(frequency.model.data$claim_freq, na.rm = TRUE)
sd_claim <- sd(frequency.model.data$claim_freq, na.rm = TRUE)
ggplot(frequency.model.data, aes(x = claim_freq)) +
geom_density(fill = "lightblue", color = "darkblue", alpha = 0.6) +
stat_function(fun = dnorm, args = list(mean = mean_claim, sd = sd_claim),
color = "red", linetype = "dashed", size = 1) +
labs(title = "Density Plot of Claim Frequency with Normal Curve",
x = "Claim Frequency",
y = "Density") +
theme_minimal() +
xlim(0, 1)
# ==================================================================================================
# GLM - Tweedie
# ==================================================================================================
var_powers <- seq(1, 2, by = 0.1)
mse_results <- numeric(length(var_powers))
train_control <- trainControl(method = "cv", number = 5)
for (i in seq_along(var_powers)) {
current_power <- var_powers[i]
model <- train(
claim_freq ~ ., data = freq_training_val,
method = "glm",
family = tweedie(var.power = current_power, link = "log"),
trControl = train_control,
metric = "RMSE"
)
mse_results[i] <- mean(model$resample$RMSE^2)
}
optimal_var_power <- var_powers[which.min(mse_results)]
optimal_var_power
tweedie_freq_model <- glm(claim_freq ~ ., data = freq_training_val, family = tweedie(var.power = optimal_var_power, link = "log"))
#Tweedie GLM Summary
summary(tweedie_freq_model)
#GLM Training Performance
tweedie_freq_model_training_predictions <- pmax(predict(tweedie_freq_model,  newdata = freq_training_val, type = "response"),0)
tweedie_freq_model_training_predictions <- as.vector(tweedie_freq_model_training_predictions)
training_MSE_tweedie <- mean((tweedie_freq_model_training_predictions-freq_training_val$claim_freq)^2)
#Performance on the test data
tweedie_freq_model_prediction <- predict(tweedie_freq_model,  newdata = freq_test, type = "response")
tweedie_freq_model_prediction <- as.vector(tweedie_freq_model_prediction)
test_MSE_tweedie <- mean((tweedie_freq_model_prediction-freq_test$claim_freq)^2)
sdu <- summary(tweedie_freq_model)
tweedie_freq_model$deviance
#ADJ R^2
RSS <- sum((freq_training_val$claim_freq - tweedie_freq_model_training_predictions)^2)
SST <- sum(freq_training_val$claim_freq - mean(freq_training_val$claim_freq)^2)
R2 <- 1 - (RSS / SST)
n <- nrow(freq_training_val)
k <- length(coef(tweedie_freq_model)) - 1
R2_adj <- 1 - ((1 - R2) * (n - 1) / (n - k - 1))
#GLM Test Performance
freq_glm_test_residuals <- freq_test$claim_freq - pmax(predict(tweedie_freq_model, newdata = freq_test, type = "response"),0)
glm_freq_test_results <- data.frame(test_residuals = freq_glm_test_residuals, Actual_Claim_Freq = freq_test$claim_freq)
ggplot(glm_freq_test_results, aes(x = Actual_Claim_Freq, y = test_residuals)) +
geom_point(color = "blue", alpha = 0.6, size = 2) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(
title = "Tweedie GLM Residuals vs. Claim Frequency",
x = "Actual Claim Frequency",
y = "New Residuals"
) +
theme_minimal(base_size = 15) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title.x = element_text(margin = ggplot2::margin(t = 10)),
axis.title.y = element_text(margin = ggplot2::margin(r = 10))
)
mse_freq_glm <- mean((glm_freq_test_results$test_residuals)^2)
# Calculate residuals from the Tweedie GLM model
freq_training_val$residuals <- freq_training_val$claim_freq - predict(tweedie_freq_model, newdata = freq_training_val, type = "response")
gbm_grid <- expand.grid(
n.trees = c(500, 1000, 1500),
interaction.depth = c(2, 3, 4),
shrinkage = c(0.01, 0.05, 0.1),
n.minobsinnode = c(5, 10)
)
# Train GBM model on residuals
gbm_residuals_model <- train(
as.formula("residuals ~ ."),
data = freq_training_val,
method = "gbm",
distribution = "gaussian",
trControl = trainControl(method = "cv", number = 5, verboseIter = FALSE),
tuneGrid = gbm_grid,
verbose = FALSE
)
predicted_test_freq_glm <- predict(tweedie_freq_model, newdata = freq_test, type = "response") #Predicting Claim_freq
freq_test_gbm_residuals <- predict(gbm_residuals_model, newdata = freq_test) #Predicting the residuals
final_test_freq_predictions_gbm <- predicted_test_freq_glm + freq_test_gbm_residuals #Final prediction = claim_freq+error
final_test_freq_predictions_gbm <- pmax(final_test_freq_predictions_gbm, 0) #claim_freq non negative
final_freq_test_residuals <- freq_test$claim_freq -  final_test_freq_predictions_gbm #Final Model with GBM residuals
test_mse_final_gbm <- mean((final_freq_test_residuals)^2)
test_mse_final_gbm
predicted_values_glm_sample <- predict(tweedie_freq_model, newdata = freq_pred_data, type = "response")
predicted_gbm_residuals_sample <- predict(gbm_residuals_model, newdata = freq_pred_data)
freq_training_val[,-which(colnames(freq_training_val) == "claim_freq")]
vars.to.remove <- c("exposure_id", "pet_gender", "pet_de_sexed_age", "pet_is_switcher", "nb_address_type_adj", "nb_suburb", "nb_state", "person_dob", "owner_age_years", "nb_breed_type",
"nb_breed_trait", "nb_breed_name_unique", "nb_breed_name_unique_concat", "exposure_id_1", "earned_units", "Total_Earned", "claim_nb", "Total_claim_amount",
"Total_claim_paid", "severity", "frequency", "is_multi_plan", "quote_time_group", "sa2_code", "nb_postcode", "is_multi_pet_plan", "pet_age_year")
frequency.model.data <- combined_data[,-which(colnames(combined_data) %in% vars.to.remove)]
frequency.model.data$qi <- ifelse(frequency.model.data$qi == "Good", 1,
ifelse(frequency.model.data$qi == "Acceptable", 2,
ifelse(frequency.model.data$qi == "Poor", 3, NA)))
frequency.model.data$qi <- as.numeric(frequency.model.data$qi)
frequency.model.data$pet_de_sexed <- ifelse(frequency.model.data$pet_de_sexed == "true", 2, ifelse(frequency.model.data$pet_de_sexed == "false", 1, NA))
frequency.model.data$pet_de_sexed <- as.numeric(frequency.model.data$pet_de_sexed)
frequency.model.data <- frequency.model.data %>%  #Convert all NA's to the mean of the column
mutate_if(is.numeric, ~ ifelse(is.na(.), mean(., na.rm = TRUE), .))
#######TESTING REMOVAL OF PREDICTORS########
additional.var.to.remove <- c("qi", "nb_state_num", "size_encoding", "lead_date_day", "UW_Date", "quote_time_group_num", "density", "is_multi_pet_plan_num")
frequency.model.data <- frequency.model.data[,-which(colnames(frequency.model.data) %in% additional.var.to.remove)]
#Splitting into test and training
set.seed(2131)
freq_training_val_index <- sample(1:nrow(frequency.model.data), 0.7*nrow(frequency.model.data))
freq_training_val <- frequency.model.data[freq_training_val_index, ]
freq_test <- frequency.model.data[-freq_training_val_index, ]
#Assessing Distribution of claim_freq
mean_claim <- mean(frequency.model.data$claim_freq, na.rm = TRUE)
sd_claim <- sd(frequency.model.data$claim_freq, na.rm = TRUE)
ggplot(frequency.model.data, aes(x = claim_freq)) +
geom_density(fill = "lightblue", color = "darkblue", alpha = 0.6) +
stat_function(fun = dnorm, args = list(mean = mean_claim, sd = sd_claim),
color = "red", linetype = "dashed", size = 1) +
labs(title = "Density Plot of Claim Frequency with Normal Curve",
x = "Claim Frequency",
y = "Density") +
theme_minimal() +
xlim(0, 1)
# ==================================================================================================
# GLM - Tweedie
# ==================================================================================================
var_powers <- seq(1, 2, by = 0.1)
mse_results <- numeric(length(var_powers))
train_control <- trainControl(method = "cv", number = 5)
for (i in seq_along(var_powers)) {
current_power <- var_powers[i]
model <- train(
claim_freq ~ ., data = freq_training_val,
method = "glm",
family = tweedie(var.power = current_power, link = "log"),
trControl = train_control,
metric = "RMSE"
)
mse_results[i] <- mean(model$resample$RMSE^2)
}
optimal_var_power <- var_powers[which.min(mse_results)]
optimal_var_power
tweedie_freq_model <- glm(claim_freq ~ ., data = freq_training_val, family = tweedie(var.power = optimal_var_power, link = "log"))
#Tweedie GLM Summary
summary(tweedie_freq_model)
#GLM Training Performance
tweedie_freq_model_training_predictions <- pmax(predict(tweedie_freq_model,  newdata = freq_training_val, type = "response"),0)
tweedie_freq_model_training_predictions <- as.vector(tweedie_freq_model_training_predictions)
training_MSE_tweedie <- mean((tweedie_freq_model_training_predictions-freq_training_val$claim_freq)^2)
#Performance on the test data
tweedie_freq_model_prediction <- predict(tweedie_freq_model,  newdata = freq_test, type = "response")
tweedie_freq_model_prediction <- as.vector(tweedie_freq_model_prediction)
test_MSE_tweedie <- mean((tweedie_freq_model_prediction-freq_test$claim_freq)^2)
sdu <- summary(tweedie_freq_model)
tweedie_freq_model$deviance
#ADJ R^2
RSS <- sum((freq_training_val$claim_freq - tweedie_freq_model_training_predictions)^2)
SST <- sum(freq_training_val$claim_freq - mean(freq_training_val$claim_freq)^2)
R2 <- 1 - (RSS / SST)
n <- nrow(freq_training_val)
k <- length(coef(tweedie_freq_model)) - 1
R2_adj <- 1 - ((1 - R2) * (n - 1) / (n - k - 1))
#GLM Test Performance
freq_glm_test_residuals <- freq_test$claim_freq - pmax(predict(tweedie_freq_model, newdata = freq_test, type = "response"),0)
glm_freq_test_results <- data.frame(test_residuals = freq_glm_test_residuals, Actual_Claim_Freq = freq_test$claim_freq)
ggplot(glm_freq_test_results, aes(x = Actual_Claim_Freq, y = test_residuals)) +
geom_point(color = "blue", alpha = 0.6, size = 2) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(
title = "Tweedie GLM Residuals vs. Claim Frequency",
x = "Actual Claim Frequency",
y = "New Residuals"
) +
theme_minimal(base_size = 15) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title.x = element_text(margin = ggplot2::margin(t = 10)),
axis.title.y = element_text(margin = ggplot2::margin(r = 10))
)
mse_freq_glm <- mean((glm_freq_test_results$test_residuals)^2)
# Calculate residuals from the Tweedie GLM model
freq_training_val$residuals <- freq_training_val$claim_freq - predict(tweedie_freq_model, newdata = freq_training_val, type = "response")
# ==================================================================================================
# GBM Training - Frequency GBM
# ==================================================================================================
# Hyperparameter tuning
gbm_grid <- expand.grid(
n.trees = c(500, 1000, 1500),
interaction.depth = c(2, 3, 4),
shrinkage = c(0.01, 0.05, 0.1),
n.minobsinnode = c(5, 10)
)
# Train GBM model on residuals
gbm_residuals_model <- train(
as.formula("residuals ~ ."),
data = freq_training_val[,-which(colnames(freq_training_val) == "claim_freq")],
method = "gbm",
distribution = "gaussian",
trControl = trainControl(method = "cv", number = 5, verboseIter = FALSE),
tuneGrid = gbm_grid,
verbose = FALSE
)
predicted_test_freq_glm <- predict(tweedie_freq_model, newdata = freq_test, type = "response") #Predicting Claim_freq
freq_test_gbm_residuals <- predict(gbm_residuals_model, newdata = freq_test[,-which(colnames(freq_test) == "claim_freq")]) #Predicting the residuals
final_test_freq_predictions_gbm <- predicted_test_freq_glm + freq_test_gbm_residuals #Final prediction = claim_freq+error
final_test_freq_predictions_gbm <- pmax(final_test_freq_predictions_gbm, 0) #claim_freq non negative
final_freq_test_residuals <- freq_test$claim_freq -  final_test_freq_predictions_gbm #Final Model with GBM residuals
test_gbm_freq_summary <- data.frame(test_residuals = final_freq_test_residuals, Actual_Claim_Freq = freq_test$claim_freq) #Data frame of actual claim_Freq and residuals
ggplot(test_gbm_freq_summary, aes(x = Actual_Claim_Freq, y = test_residuals)) +   ###Visualisation of glm with gbm performance on the test data
geom_point(color = "blue", alpha = 0.6, size = 2) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(
title = "GLM with GBM Residuals vs. Claim Frequency",
x = "Actual Claim Frequency",
y = "New Residuals"
) +
theme_minimal(base_size = 15) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title.x = element_text(margin = ggplot2::margin(t = 10)),
axis.title.y = element_text(margin = ggplot2::margin(r = 10))
)
test_mse_final_gbm <- mean((final_freq_test_residuals)^2)
test_mse_final_gbm
mse_freq_glm
final_sample_predictions <- predicted_values_glm_sample + predicted_gbm_residuals_sample
predicted_values_glm_sample <- predict(tweedie_freq_model, newdata = freq_pred_data, type = "response")
predicted_gbm_residuals_sample <- predict(gbm_residuals_model, newdata = freq_pred_data)
final_sample_predictions <- predicted_values_glm_sample + predicted_gbm_residuals_sample
final_sample_predictions <- pmax(final_sample_predictions, 0)
final_sample_predictions
min(final_sample_predictions)
min(final_sample_predictions)
max(final_sample_predictions)
