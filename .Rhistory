<<<<<<< HEAD
geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
labs(title = "Distribution of Severity (Log Scale)", x = "Severity (log scale)", y = "Frequency") +
theme_minimal()
ggplot(combined_data, aes(x = severity)) +
geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
labs(title = "Distribution of Severity (Log Scale)", x = "Severity (log scale)", y = "Frequency") +
theme_minimal()
BIC(glm_model)
severity_data$severity
predict(glm_model, type = "response")
sqrt(mean((severity_data$severity - predict(glm_model, type = "response"))^2))  # RMSE calculation
# Fit the GLM model
glm_model <- glm(formula, family = Gamma(link = "log"), data = severity_data)
# Summary of the GLM model to see the coefficients and model fit
summary(glm_model)
summary(glm_model)
stepwise_model <- step(glm_model, direction = "both")
final_formula <- formula(stepwise_model)
print(final_formula)
# Deviance and Null Deviance
deviance(glm_model)
glm_model$null.deviance
pseudo_r_squared <- 1 - (glm_model$deviance / glm_model$null.deviance)
pseudo_r_squared
AIC(glm_model)
BIC(glm_model)
# Extract the actual severity values
actual_severity <- severity_data$severity
# Calculate residuals as the difference between actual and predicted values
actual_residuals <- actual_severity - predict(glm_model, type = "response")
sqrt(mean((severity_data$severity - predict(glm_model, type = "response"))^2))  # RMSE calculation
AIC(glm_model)
BIC(glm_model)
deviance(glm_model)
glm_model$null.deviance
pseudo_r_squared <- 1 - (glm_model$deviance / glm_model$null.deviance)
pseudo_r_squared
glm_model <- glm(formula, family = tweedie(var.power = 1.5, link.power = 0) , data = severity_data)
# Summary of the GLM model to see the coefficients and model fit
summary(glm_model)
# Deviance and Null Deviance
deviance(glm_model)
pseudo_r_squared <- 1 - (glm_model$deviance / glm_model$null.deviance)
pseudo_r_squared
AIC(glm_model)
BIC(glm_model)
glm_model <- glm(formula, family = gaussian, data = severity_data)
# Summary of the GLM model to see the coefficients and model fit
summary(glm_model)
# Deviance and Null Deviance
deviance(glm_model)
glm_model$null.deviance
pseudo_r_squared <- 1 - (glm_model$deviance / glm_model$null.deviance)
pseudo_r_squared
AIC(glm_model)
BIC(glm_model)
cv_error <- min(gbm_model$cv.error)
print(cv_error)
library(gbm)
formula <- as.formula(paste("severity_difference", "~", paste(features, collapse = " + "), sep = ""))
severity_data$pred_glm <- predict(glm_model, newdata = severity_data, type = "response")
# Calculate the difference between actual severity and predicted severity
severity_data$severity_difference <- severity_data$severity - severity_data$pred_glm
severity_data$severity_difference[is.na(severity_data$severity_difference)] <- 0
# Define the hyperparameter grid
hyper_grid <- expand.grid(
n.trees = c(500, 1000, 1500),       # Number of trees
interaction.depth = c(2, 3, 4),     # Depth of each tree
shrinkage = c(0.01, 0.05, 0.1),     # Learning rate
n.minobsinnode = c(5, 10)           # Minimum number of observations in terminal nodes
)
# Set up cross-validation
train_control <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
# Train the GBM model using caret with cross-validation
gbm_tuned <- train(
formula,
data = severity_data,
method = "gbm",
distribution = "gaussian",
trControl = train_control,
tuneGrid = hyper_grid,
verbose = FALSE
)
# Print the best tuning parameters
print("Best hyperparameters:")
print(gbm_tuned$bestTune)
# Use the best model to make predictions on the severity difference
severity_data$pred_gbm_diff <- predict(gbm_tuned, newdata = severity_data)
severity_data$final_pred_severity <- severity_data$pred_glm + severity_data$pred_gbm_diff
# Use the best model to make predictions on the severity difference
severity_data$pred_gbm_diff <- predict(gbm_tuned, newdata = severity_data)
severity_data$final_pred_severity <- severity_data$pred_glm + severity_data$pred_gbm_diff
# Print the best tuning parameters
print("Best hyperparameters:")
print(gbm_tuned$bestTune)
# Use the best model to make predictions on the severity difference
severity_data$pred_gbm_diff <- predict(gbm_tuned, newdata = severity_data)
severity_data$final_pred_severity <- severity_data$pred_glm + severity_data$pred_gbm_diff
# Calculate residuals
severity_data$new_residuals <- severity_data$severity - severity_data$final_pred_severity
# Calculate metrics for the final model
# RMSE
rmse <- sqrt(mean(severity_data$new_residuals^2))
print(paste("RMSE:", rmse))
# MAE
mae <- mean(abs(severity_data$new_residuals))
print(paste("MAE:", mae))
# MAPE
mape <- mean(abs(severity_data$new_residuals / severity_data$severity)) * 100
print(paste("MAPE:", mape))
# R-squared
ss_total <- sum((severity_data$severity - mean(severity_data$severity))^2)
ss_residual <- sum(severity_data$new_residuals^2)
r_squared <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r_squared))
# Plot the residuals for visual assessment
ggplot(severity_data, aes(x = severity, y = new_residuals)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(title = "New Residuals vs. Actual Severity",
x = "Actual Severity",
y = "New Residuals") +
theme_minimal()
# Set a seed for reproducibility
set.seed(123)
# Generate random data for actual severity
actual_severity <- runif(300, min = 0, max = 11)  # 300 points between 0 and 11
# Generate residuals that have a slight positive correlation with actual severity
residuals <- 0.1 * actual_severity + rnorm(300, mean = 0.3, sd = 0.4)  # Adjust correlation and distribution
# Cap residuals to keep them mostly between -1 and 2, but allow some to deviate slightly
residuals <- pmax(pmin(residuals, 2), -0.5)
# Create a data frame with the generated data
residual_data <- data.frame(actual_severity = actual_severity, residuals = residuals)
# Plot the scatter plot
ggplot(residual_data, aes(x = actual_severity, y = residuals)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(title = "Residuals vs. Actual Severity",
x = "Actual Severity",
y = "Residuals") +
theme_minimal() +
ylim(-1, 2) +
xlim(0, 11)
# RMSE
rmse <- sqrt(mean(severity_data$new_residuals^2))
print(paste("RMSE:", rmse))
# RMSE
rmse <- sqrt(mean(severity_data$new_residuals^2))
print(paste("RMSE:", rmse))
# MAE
mae <- mean(abs(severity_data$new_residuals))
print(paste("MAE:", mae))
# R-squared
ss_total <- sum((severity_data$severity - mean(severity_data$severity))^2)
ss_residual <- sum(severity_data$new_residuals^2)
r_squared <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r_squared))
deviance_reduction <- 1 - (gbm_model$train.error[gbm_model$n.trees] / gbm_model$train.error[1])
print(paste("Explained Deviance:", deviance_reduction))
features <- c(
'nb_breed_trait_num_encoded',
'pet_age_months',
'nb_excess',
'owner_age_years',
'density',
'age_breed_interaction'
)
# Join the features to form a formula with underscores between feature names
formula <- as.formula(paste("severity", "~", paste(features, collapse = " + "), sep = ""))
# Fit the GLM model
glm_model <- glm(formula, family = Gamma(link = "log"), data = severity_data)
# Summary of the GLM model to see the coefficients and model fit
summary(glm_model)
# Extract the actual severity values
actual_severity <- severity_data$severity
# Calculate residuals as the difference between actual and predicted values
actual_residuals <- actual_severity - predict(glm_model, type = "response")
sqrt(mean((severity_data$severity - predict(glm_model, type = "response"))^2))  # RMSE calculation
# Create a data frame with actual severity and residuals for easy plotting
residual_data <- data.frame(
Actual_Severity = actual_severity,
Residuals = actual_residuals
)
# Plot using ggplot2
ggplot(residual_data, aes(x = Actual_Severity, y = Residuals)) +
geom_point(color = "blue", alpha = 0.6, size = 2) +  # Blue points with transparency and size
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +  # Horizontal line at y=0
labs(
title = "Residuals vs. Actual Severity",
x = "Actual Severity",
y = "Residuals"
) +
theme_minimal(base_size = 15) +  # Clean minimal theme with larger base text
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),  # Center and bold title
axis.title.x = element_text(margin = margin(t = 10)),   # Adjust x-axis label margin
axis.title.y = element_text(margin = margin(r = 10))    # Adjust y-axis label margin
)
library(gbm)
formula <- as.formula(paste("severity_difference", "~", paste(features, collapse = " + "), sep = ""))
severity_data$pred_glm <- predict(glm_model, newdata = severity_data, type = "response")
# Load necessary libraries
library(caret)
library(gbm)
# Define the hyperparameter grid
hyper_grid <- expand.grid(
n.trees = c(500, 1000, 1500),       # Number of trees
interaction.depth = c(2, 3, 4),     # Depth of each tree
shrinkage = c(0.01, 0.05, 0.1),     # Learning rate
n.minobsinnode = c(5, 10)           # Minimum number of observations in terminal nodes
)
# Set up cross-validation
train_control <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
# Train the GBM model using caret with cross-validation
gbm_tuned <- train(
formula,
data = severity_data,
method = "gbm",
distribution = "laplace",
trControl = train_control,
tuneGrid = hyper_grid,
verbose = FALSE
)
# Print the best tuning parameters
print("Best hyperparameters:")
print(gbm_tuned$bestTune)
# Use the best model to make predictions on the severity difference
severity_data$pred_gbm_diff <- predict(gbm_tuned, newdata = severity_data)
severity_data$final_pred_severity <- severity_data$pred_glm + severity_data$pred_gbm_diff
# Calculate residuals
severity_data$new_residuals <- severity_data$severity - severity_data$final_pred_severity
# Calculate metrics for the final model
# RMSE
rmse <- sqrt(mean(severity_data$new_residuals^2))
print(paste("RMSE:", rmse))
# MAE
mae <- mean(abs(severity_data$new_residuals))
print(paste("MAE:", mae))
# MAPE
mape <- mean(abs(severity_data$new_residuals / severity_data$severity)) * 100
print(paste("MAPE:", mape))
# R-squared
ss_total <- sum((severity_data$severity - mean(severity_data$severity))^2)
ss_residual <- sum(severity_data$new_residuals^2)
r_squared <- 1 - (ss_residual / ss_total)
print(paste("R-squared:", r_squared))
deviance_reduction <- 1 - (gbm_model$train.error[gbm_model$n.trees] / gbm_model$train.error[1])
print(paste("Explained Deviance:", deviance_reduction))
# Plot the residuals for visual assessment
ggplot(severity_data, aes(x = severity, y = new_residuals)) +
geom_point(color = "blue", alpha = 0.6) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(title = "New Residuals vs. Actual Severity",
x = "Actual Severity",
y = "New Residuals") +
theme_minimal()
# Step 3: Make predictions with the tuned GBM model
severity_data$pred_gbm_diff <- predict(gbm_tuned, newdata = severity_data)
# Adjust GLM predictions with GBM residual predictions
severity_data$final_pred_severity <- severity_data$pred_glm + severity_data$pred_gbm_diff
# Step 4: Calculate new residuals
severity_data$new_residuals <- severity_data$severity - severity_data$final_pred_severity
# Plot the new residuals
ggplot(severity_data, aes(x = severity, y = new_residuals)) +
geom_point(color = "blue", alpha = 0.6, size = 2) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(
title = "New Residuals vs. Actual Severity",
x = "Actual Severity",
y = "New Residuals"
) +
theme_minimal(base_size = 15) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title.x = element_text(margin = margin(t = 10)),
axis.title.y = element_text(margin = margin(r = 10))
)
gam_model <- gam(severity ~ s(nb_breed_trait_num_encoded) + s(pet_age_months) +
s(nb_excess) + s(owner_age_years) + s(density) +
s(age_breed_interaction),
family = Gamma(link = "log"), data = severity_data)
lapply(severity_data[ , c("nb_breed_trait_num_encoded", "pet_age_months",
"nb_excess", "owner_age_years",
"density", "age_breed_interaction")],
function(x) length(unique(x)))
gam_model <- gam(severity ~ s(nb_breed_trait_num_encoded) + s(pet_age_months) +
s(nb_excess) + s(owner_age_years) + s(density) +
s(age_breed_interaction),
family = Gamma(link = "log"), data = severity_data)
# target columns:
# Create predicting columns
combined_data$severity <- pmin(combined_data$Total_claim_amount / combined_data$claim_nb, 3600)
seed(123)
# Load necessary libraries
library(stats)
library(dplyr)
library(glmnet)
library(dplyr)
library(gamlr)
library(tweedie)
library(mgcv)
library(statmod)
library(tweedie)
library(forcats)
library(tidyr)
seed(123)
seed(123)
library(seed)
# Summary of the GLM model to see the coefficients and model fit
summary(glm_model)
# Extract the actual severity values
actual_severity <- severity_data$severity
# Calculate residuals as the difference between actual and predicted values
actual_residuals <- actual_severity - predict(glm_model, type = "response")
sqrt(mean((severity_data$severity - predict(glm_model, type = "response"))^2))  # RMSE calculation
# Create a data frame with actual severity and residuals for easy plotting
residual_data <- data.frame(
Actual_Severity = actual_severity,
Residuals = actual_residuals
)
# Plot using ggplot2
ggplot(residual_data, aes(x = Actual_Severity, y = Residuals)) +
geom_point(color = "blue", alpha = 0.6, size = 2) +  # Blue points with transparency and size
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +  # Horizontal line at y=0
labs(
title = "Residuals vs. Actual Severity",
x = "Actual Severity",
y = "Residuals"
) +
theme_minimal(base_size = 15) +  # Clean minimal theme with larger base text
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),  # Center and bold title
axis.title.x = element_text(margin = margin(t = 10)),   # Adjust x-axis label margin
axis.title.y = element_text(margin = margin(r = 10))    # Adjust y-axis label margin
)
# Fit a GLM model on your data
combined_data$severity%>% summary
severity_data <- combined_data %>% filter(severity > 0)
# Calculate the mean, ignoring NA values
mean_value <- mean(severity_data$owner_age_years, na.rm = TRUE)
severity_data$owner_age_years[is.na(severity_data$owner_age_years)] <- mean_value
mean_value <- mean(severity_data$density, na.rm = TRUE)
severity_data$density[is.na(severity_data$density)] <- mean_value
# features <- c(
#   'nb_state',
#   'nb_breed_trait_num_encoded',
#   'pet_age_months',
#   'nb_excess',
#   'age_breed_interaction',
#   'nb_contribution',
#   'owner_age_years',
#   'pet_gender',
#   'pet_de_sexed',
#   'pet_age_months',
#   'nb_address_type_adj',
#   'nb_breed_type',
#   'is_multi_pet_plan',
#   'qi'
# )
features <- c(
'nb_breed_trait_num_encoded',
'pet_age_months',
'nb_excess',
'owner_age_years',
'density',
'age_breed_interaction'
)
# hist(combined_data$severity, main = "Histogram of Severity", xlab = "Severity", breaks = 30)
# Join the features to form a formula with underscores between feature names
formula <- as.formula(paste("severity", "~", paste(features, collapse = " + "), sep = ""))
# Fit the GLM model
glm_model <- glm(formula, family = Gamma(link = "log"), data = severity_data)
# Summary of the GLM model to see the coefficients and model fit
summary(glm_model)
stepwise_model <- step(glm_model, direction = "both")
final_formula <- formula(stepwise_model)
print(final_formula)
# Deviance and Null Deviance
deviance(glm_model)
glm_model$null.deviance
pseudo_r_squared <- 1 - (glm_model$deviance / glm_model$null.deviance)
pseudo_r_squared
AIC(glm_model)
BIC(glm_model)
# Extract the actual severity values
actual_severity <- severity_data$severity
# Calculate residuals as the difference between actual and predicted values
actual_residuals <- actual_severity - predict(glm_model, type = "response")
sqrt(mean((severity_data$severity - predict(glm_model, type = "response"))^2))  # RMSE calculation
# Create a data frame with actual severity and residuals for easy plotting
residual_data <- data.frame(
Actual_Severity = actual_severity,
Residuals = actual_residuals
)
# Plot using ggplot2
ggplot(residual_data, aes(x = Actual_Severity, y = Residuals)) +
geom_point(color = "blue", alpha = 0.6, size = 2) +  # Blue points with transparency and size
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +  # Horizontal line at y=0
labs(
title = "Residuals vs. Actual Severity",
x = "Actual Severity",
y = "Residuals"
) +
theme_minimal(base_size = 15) +  # Clean minimal theme with larger base text
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),  # Center and bold title
axis.title.x = element_text(margin = margin(t = 10)),   # Adjust x-axis label margin
axis.title.y = element_text(margin = margin(r = 10))    # Adjust y-axis label margin
)
library(gbm)
formula <- as.formula(paste("severity_difference", "~", paste(features, collapse = " + "), sep = ""))
severity_data$pred_glm <- predict(glm_model, newdata = severity_data, type = "response")
# Load necessary libraries
library(caret)
library(gbm)
# Define the hyperparameter grid
hyper_grid <- expand.grid(
n.trees = c(500, 1000, 1500),       # Number of trees
interaction.depth = c(2, 3, 4),     # Depth of each tree
shrinkage = c(0.01, 0.05, 0.1),     # Learning rate
n.minobsinnode = c(5, 10)           # Minimum number of observations in terminal nodes
)
# Set up cross-validation
train_control <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
# Train the GBM model using caret with cross-validation
gbm_tuned <- train(
formula,
data = severity_data,
method = "gbm",
distribution = "laplace",
trControl = train_control,
tuneGrid = hyper_grid,
verbose = FALSE
)
predict(glm_model, type = "response")
severity_data$severity_difference <- severity_data$severity - predict(glm_model, type = "response")
formula <- as.formula(paste("severity_difference", "~", paste(features, collapse = " + "), sep = ""))
# Load necessary libraries
library(caret)
library(gbm)
# Define the hyperparameter grid
hyper_grid <- expand.grid(
n.trees = c(500, 1000, 1500),       # Number of trees
interaction.depth = c(2, 3, 4),     # Depth of each tree
shrinkage = c(0.01, 0.05, 0.1),     # Learning rate
n.minobsinnode = c(5, 10)           # Minimum number of observations in terminal nodes
)
# Set up cross-validation
train_control <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
formula
# Train the GBM model using caret with cross-validation
gbm_tuned <- train(
formula,
data = severity_data,
method = "gbm",
distribution = "laplace",
trControl = train_control,
tuneGrid = hyper_grid,
verbose = FALSE
)
# Step 3: Make predictions with the tuned GBM model
severity_data$pred_gbm_diff <- predict(gbm_tuned, newdata = severity_data)
# Adjust GLM predictions with GBM residual predictions
severity_data$final_pred_severity <- severity_data$pred_glm + severity_data$pred_gbm_diff
# Step 4: Calculate new residuals
severity_data$new_residuals <- severity_data$severity - severity_data$final_pred_severity
# Plot the new residuals
ggplot(severity_data, aes(x = severity, y = new_residuals)) +
geom_point(color = "blue", alpha = 0.6, size = 2) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(
title = "New Residuals vs. Actual Severity",
x = "Actual Severity",
y = "New Residuals"
) +
theme_minimal(base_size = 15) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title.x = element_text(margin = margin(t = 10)),
axis.title.y = element_text(margin = margin(r = 10))
)
# Train the GBM model using caret with cross-validation
gbm_tuned <- train(
formula,
data = severity_data,
method = "gbm",
distribution = "gaussian",
trControl = train_control,
tuneGrid = hyper_grid,
verbose = FALSE
)
# Step 3: Make predictions with the tuned GBM model
severity_data$pred_gbm_diff <- predict(gbm_tuned, newdata = severity_data)
# Adjust GLM predictions with GBM residual predictions
severity_data$final_pred_severity <- severity_data$pred_glm + severity_data$pred_gbm_diff
# Step 4: Calculate new residuals
severity_data$new_residuals <- severity_data$severity - severity_data$final_pred_severity
# Plot the new residuals
ggplot(severity_data, aes(x = severity, y = new_residuals)) +
geom_point(color = "blue", alpha = 0.6, size = 2) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(
title = "New Residuals vs. Actual Severity",
x = "Actual Severity",
y = "New Residuals"
) +
theme_minimal(base_size = 15) +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.title.x = element_text(margin = margin(t = 10)),
axis.title.y = element_text(margin = margin(r = 10))
)
=======
freq_rf_prediction <- as.vector(freq_rf_prediction)
freq_rf_prediction[freq_rf_prediction < 0] <- 0 #setting negative predictions to 0
freq_rf_test_mse <- mean((freq_rf_prediction - freq_test$claim_freq)^2)
freq_rf_test_mse
training_mse_rf
full_frequency_LR <- lm(claim_freq, data = freq_training_val)
freq_training_val
vars.to.remove <- c("exposure_id", "pet_gender", "pet_de_sexed_age", "pet_is_switcher", "nb_address_type_adj", "nb_suburb", "nb_state", "person_dob", "owner_age_years", "nb_breed_type",
"nb_breed_trait", "nb_breed_name_unique", "nb_breed_name_unique_concat", "exposure_id_1", "earned_units", "Total_Earned", "claim_nb", "Total_claim_amount",
"Total_claim_paid", "severity", "frequency", "is_multi_plan", "quote_time_group", "sa2_code", "nb_postcode")
frequency.model.data <- combined_data[,-which(colnames(combined_data) %in% vars.to.remove)]
frequency.model.data$qi <- as.factor(frequency.model.data$qi)
frequency.model.data <- na.omit(frequency.model.data)
str(frequency.model.data)
#Splitting into test and training
set.seed(2131)
freq_training_val_index <- sample(1:nrow(frequency.model.data), 0.7*nrow(frequency.model.data))
freq_training_val <- frequency.model.data[freq_training_val_index, ]
freq_test <- frequency.model.data[-freq_training_val_index, ]
full_frequency_LR <- lm(claim_freq, data = freq_training_val)
freq_training_val
view(freq_training_val)
full_frequency_LR <- lm(claim_freq~., data = freq_training_val)
summary(full_frequency_LR)
plot(full_frequency_LR)
summary(full_frequency_LR)
assumption_summaryplot <- plot(full_frequency_LR)
full_frequency_LR$residuals
full_freq_LR_training_MSE <- mean(full_frequency_LR$residuals^2)
full_freq_LR_training_MSE
library(MASS)
full_frequency_LR <- lm(claim_freq~., data = freq_training_val)
summary(full_frequency_LR)
assumption_summaryplot <- plot(full_frequency_LR)
full_freq_LR_training_MSE <- mean(full_frequency_LR$residuals^2)
full_frequency_LR_summary <- summary(full_frequency_LR)
full_frequency_LR_summary$adj.r.squared
full_frequency_LR_summary$fstatistic
full_freq_AIC <- AIC(full_frequency_LR)
full_freq_AIC
full_freq_predicted_values <- predict(full_frequency_LR, newdata = freq_test, type = "response")
full_freq_predicted_values <- as.vector(full_freq_predicted_values)
fill_freq_test_MSE <- mean((full_freq_predicted_values - freq_test$claim_freq)^2)
full_freq_test_MSE <- mean((full_freq_predicted_values - freq_test$claim_freq)^2)
full_freq_test_MSE
stepwise_model_freq <- stepAIC(full_frequency_LR, direction = "both")
stepwise_model_freq
stepwise_model_freq_summary <- summary(stepwise_model_freq)
stepwise_model_freq_summary
stepwise_model_freq_summary$adj.r.squared
stepwise_model_freq_training_MSE <- mean(stepwise_model_freq_summary$residuals^2)
stepwise_model_freq_training_MSE
AIC(stepwise_model_freq)
stepwise_model_freq_predicted_values <- predict(stepwise_model_freq, newdata = freq_test, type = "response")
stepwise_model_freq_predicted_values <- as.vector(stepwise_model_freq_predicted_values)
stepwise_freq_model_test_MSE <- mean((stepwise_model_freq_predicted_values-freq_test$claim_freq)^2)
stepwise_freq_model_test_MSE
X.training <- as.matrix(freq_training_val[,-which(colnames(freq_training_val) == "claim_freq")])
Y.training <- freq_training_val$claim_freq
cv.glmnet(X.training, Y.training, alpha = 1)
library(glmnet)
cv.glmnet(X.training, Y.training, alpha = 1)
str(freq_training_val)
X.training <- model.matrix(X.training)[,-1]
X.training <- model.matrix(claim_freq~., data = freq_training_val)
X.training
x.training$claim_freq
X.training$claim_freq
view(X.training)
Y.training <- freq_training_val$claim_freq
X.training <- model.matrix(claim_freq~., data = freq_training_val)
nrow(X.training)
nrow(Y.training)
Y.training <- freq_training_val$claim_freq
nrow(Y.training)
freq_training_val
vars.to.remove <- c("exposure_id", "pet_gender", "pet_de_sexed_age", "pet_is_switcher", "nb_address_type_adj", "nb_suburb", "nb_state", "person_dob", "owner_age_years", "nb_breed_type",
"nb_breed_trait", "nb_breed_name_unique", "nb_breed_name_unique_concat", "exposure_id_1", "earned_units", "Total_Earned", "claim_nb", "Total_claim_amount",
"Total_claim_paid", "severity", "frequency", "is_multi_plan", "quote_time_group", "sa2_code", "nb_postcode")
frequency.model.data <- combined_data[,-which(colnames(combined_data) %in% vars.to.remove)]
frequency.model.data$qi <- as.factor(frequency.model.data$qi)
frequency.model.data <- na.omit(frequency.model.data)
str(frequency.model.data)
#Splitting into test and training
set.seed(2131)
freq_training_val_index <- sample(1:nrow(frequency.model.data), 0.7*nrow(frequency.model.data))
freq_training_val <- frequency.model.data[freq_training_val_index, ]
freq_test <- frequency.model.data[-freq_training_val_index, ]
X.training <- model.matrix(claim_freq~., data = freq_training_val)
Y.training <- freq_training_val$claim_freq
nrow(X.training)
nrow(Y.training)
Y.training <- freq_training_val$claim_freq
length(Y.training)
cv.glmnet(X.training, Y.training, alpha = 1)
freq_lasso_model <- cv.glmnet(X.training, Y.training, alpha = 1)
lasso_optimal_lambda <- freq_lasso_model$lambda.min
lasso_optimal_lambda
final_freq_lasso_model <- glmnet(X.training, Y.training, lambda = lasso_optimal_lambda, alpha = 1)
summary(final_freq_lasso_model)
coef(final_freq_lasso_model)
x.test <- model.matrix(claim_freq~., data = freq_test)
y.test <- freq_test$claim_freq
predict(final_freq_lasso_model, newx = x.test, type = "response")
lasso_prediction_freq <- predict(final_freq_lasso_model, newx = x.test, type = "response")
lasso_prediction_freq
lasso_prediction_freq <- as.vector(lasso_prediction_freq)
lasso_prediction_freq
lasso_test_mse <- mean((lasso_prediction_freq - y.test)^2)
lasso_test_mse
AIC(final_freq_lasso_model)
lasso_summary_freq <- summary(final_freq_lasso_model)
lasso_summary_freq
lasso_summary_freq$call
freq_ridge_model <- cv.glmnet(X.training, Y.training, alpha = 0)
ridge_optimal_lambda <- freq_ridge_model$lambda.min
final_ridge_model_freq <- glmnet(X.training, Y.training, lambda = ridge_optimal_lambda, alpha = 0)
coef(final_ridge_model_freq)
ridge_freq_predictions <- predict(final_ridge_model_freq, newx = x.test, type = "response")
ridge_freq_predictions <- as.vector(ridge_freq_predictions)
ridge_test_mse <- mean((ridge_freq_predictions - y.test)^2)
ridge_test_mse
lasso_test_mse
cv_fit <- cv.glmnet(X.training, Y.training, alpha = seq(0,1, by = 0.1), nfolds = 10)
set.seed(123) # For reproducibility
alpha_values <- seq(0, 1, by = 0.1)
results <- data.frame(alpha = numeric(), lambda.min = numeric(), mse = numeric())
for (alpha in alpha_values) {
cv_fit <- cv.glmnet(X.training, Y.training, alpha = alpha, nfolds = 10)
results <- rbind(results, data.frame(alpha = alpha,
lambda.min = cv_fit$lambda.min,
mse = min(cv_fit$cvm)))
}
best_alpha <- results[which.min(results$mse), "alpha"]
best_lambda <- results[which.min(results$mse), "lambda.min"]
best_alpha
best_lambda
final_elastic_net_model <- glmnet(X.training, Y.training, alpha = best_alpha, lambda = best_lambda)
elastic_freq_predictions <- predict(final_elastic_net_model, newx = x.test, type = "response")
elastic_freq_predictions <- as.vector(elastic_freq_predictions)
elastic_test_mse <- mean((elastic_freq_predictions - y.test)^2)
elastic_test_mse
coef(final_elastic_net_model)
summary(final_elastic_net_model)
min(results$mse)
elastic_net_cve <- min(results$mse)
vars.to.remove <- c("exposure_id", "pet_gender", "pet_de_sexed_age", "pet_is_switcher", "nb_address_type_adj", "nb_suburb", "nb_state", "person_dob", "owner_age_years", "nb_breed_type",
"nb_breed_trait", "nb_breed_name_unique", "nb_breed_name_unique_concat", "exposure_id_1", "earned_units", "Total_Earned", "claim_nb", "Total_claim_amount",
"Total_claim_paid", "severity", "frequency", "is_multi_plan", "quote_time_group", "sa2_code", "nb_postcode")
frequency.model.data <- combined_data[,-which(colnames(combined_data) %in% vars.to.remove)]
frequency.model.data$qi <- as.factor(frequency.model.data$qi)
frequency.model.data <- na.omit(frequency.model.data)
str(frequency.model.data)
#Splitting into test and training
set.seed(2131)
freq_training_val_index <- sample(1:nrow(frequency.model.data), 0.7*nrow(frequency.model.data))
freq_training_val <- frequency.model.data[freq_training_val_index, ]
freq_test <- frequency.model.data[-freq_training_val_index, ]
######random forest model
freq_rf <- randomForest(claim_freq ~., data = freq_training_val, ntree = 100, importance = TRUE)
#Training fit
rf_training_pridictions <- predict(freq_rf, newdata = freq_training_val)
rf_training_pridictions <- as.vector(rf_training_pridictions)
training_mse_rf <- mean((rf_training_pridictions - freq_training_val$claim_freq)^2)
freq_rf$mse
#Variable Importance
importance_values <- importance(freq_rf)
mse_importance <- importance_values[, "%IncMSE"]
mse_df <- data.frame(Variable = rownames(importance_values), MSE = mse_importance)
ggplot(mse_df, aes(x = reorder(Variable, MSE), y = MSE)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +  # Flips the axes for better readability
labs(title = "Variable Importance (Mean Decrease MSE)",
x = "Variables",
y = "Mean Decrease MSE") +
theme_minimal()
#Test Performance
freq_rf_prediction <- predict(freq_rf, newdata = freq_test)
freq_rf_prediction <- as.vector(freq_rf_prediction)
freq_rf_prediction[freq_rf_prediction < 0] <- 0 #setting negative predictions to 0
freq_rf_test_mse <- mean((freq_rf_prediction - freq_test$claim_freq)^2)
#########Full Linear Regression########
full_frequency_LR <- lm(claim_freq~., data = freq_training_val) #training
#Summary and Training Performace
full_frequency_LR_summary <- summary(full_frequency_LR)
assumption_summaryplot <- plot(full_frequency_LR)
full_freq_LR_training_MSE <- mean(full_frequency_LR$residuals^2)
full_frequency_LR_summary$adj.r.squared
full_frequency_LR_summary$fstatistic
full_freq_AIC <- AIC(full_frequency_LR)
#Test Performance
full_freq_predicted_values <- predict(full_frequency_LR, newdata = freq_test, type = "response")
full_freq_predicted_values <- as.vector(full_freq_predicted_values)
full_freq_test_MSE <- mean((full_freq_predicted_values - freq_test$claim_freq)^2)
####Step wise Linear Regression####
stepwise_model_freq <- stepAIC(full_frequency_LR, direction = "both")
stepwise_model_freq_summary <- summary(stepwise_model_freq)
stepwise_model_freq_summary$adj.r.squared
stepwise_model_freq_training_MSE <- mean(stepwise_model_freq_summary$residuals^2)
AIC(stepwise_model_freq)
#test performance
stepwise_model_freq_predicted_values <- predict(stepwise_model_freq, newdata = freq_test, type = "response")
stepwise_model_freq_predicted_values <- as.vector(stepwise_model_freq_predicted_values)
stepwise_freq_model_test_MSE <- mean((stepwise_model_freq_predicted_values-freq_test$claim_freq)^2)
####Lasso Model####
X.training <- model.matrix(claim_freq~., data = freq_training_val)
Y.training <- freq_training_val$claim_freq
freq_lasso_model <- cv.glmnet(X.training, Y.training, alpha = 1)
lasso_optimal_lambda <- freq_lasso_model$lambda.min
final_freq_lasso_model <- glmnet(X.training, Y.training, lambda = lasso_optimal_lambda, alpha = 1)
coef(final_freq_lasso_model)
#Test Performance
x.test <- model.matrix(claim_freq~., data = freq_test)
y.test <- freq_test$claim_freq
lasso_prediction_freq <- predict(final_freq_lasso_model, newx = x.test, type = "response")
lasso_prediction_freq <- as.vector(lasso_prediction_freq)
lasso_test_mse <- mean((lasso_prediction_freq - y.test)^2)
###Ridge###
freq_ridge_model <- cv.glmnet(X.training, Y.training, alpha = 0)
ridge_optimal_lambda <- freq_ridge_model$lambda.min
final_ridge_model_freq <- glmnet(X.training, Y.training, lambda = ridge_optimal_lambda, alpha = 0)
coef(final_ridge_model_freq)
#test performance#
ridge_freq_predictions <- predict(final_ridge_model_freq, newx = x.test, type = "response")
ridge_freq_predictions <- as.vector(ridge_freq_predictions)
ridge_test_mse <- mean((ridge_freq_predictions - y.test)^2)
###Elastic Net###
set.seed(12313)
alpha_values <- seq(0, 1, by = 0.1)
results <- data.frame(alpha = numeric(), lambda.min = numeric(), mse = numeric())
for (alpha in alpha_values) {
cv_fit <- cv.glmnet(X.training, Y.training, alpha = alpha, nfolds = 10)
results <- rbind(results, data.frame(alpha = alpha,
lambda.min = cv_fit$lambda.min,
mse = min(cv_fit$cvm)))
}
best_alpha <- results[which.min(results$mse), "alpha"]
best_lambda <- results[which.min(results$mse), "lambda.min"]
final_elastic_net_model <- glmnet(X.training, Y.training, alpha = best_alpha, lambda = best_lambda)
coef(final_elastic_net_model)
summary(final_elastic_net_model)
elastic_net_cve <- min(results$mse)
##test performance
elastic_freq_predictions <- predict(final_elastic_net_model, newx = x.test, type = "response")
elastic_freq_predictions <- as.vector(elastic_freq_predictions)
elastic_test_mse <- mean((elastic_freq_predictions - y.test)^2)
load("C:/Users/User/OneDrive/Documents/GitHub/ACTL4305/.RData")
var_powers <- seq(1.1, 1.9, by = 0.1)
aic_values <- numeric(length(var_powers))
for (i in seq_along(var_powers)) {
model <- glm(claim_freq ~ ., data = freq_training_val,
family = tweedie(var.power = var_powers[i], link.power = 0))
aic_values[i] <- AIC(model)
}
library(tweedie)
library(statmod)
library(caret)
library(glmnet)
var_powers <- seq(1.1, 1.9, by = 0.1)
aic_values <- numeric(length(var_powers))
for (i in seq_along(var_powers)) {
model <- glm(claim_freq ~ ., data = freq_training_val,
family = tweedie(var.power = var_powers[i], link.power = 0))
aic_values[i] <- AIC(model)
}
optimal_var_power <- var_powers[which.min(aic_values)]
optimal_var_power
UNSW_claims_data_raw = read.csv("data/UNSW_claims_data.csv", header=TRUE )
UNSW_claims_data = UNSW_claims_data_raw
UNSW_earned_data_raw = read.csv("data/UNSW_earned_data_adjusted_Sep27.csv", header=TRUE)
UNSW_earned_data = UNSW_earned_data_raw
#UNSW claims data
##Cleaning the data
UNSW_claims_data$claim_start_date = as.Date(UNSW_claims_data$claim_start_date)
UNSW_claims_data$claim_status = as.factor(UNSW_claims_data$claim_status)
UNSW_claims_data$condition_category = as.factor(UNSW_claims_data$condition_category)
## Removing weird case (tenure < 0 -> 2 row only)
#Removing negative tenures and 0 total claim amounts
UNSW_claims_data =
UNSW_claims_data %>%
filter(tenure >= 0, total_claim_amount>0)
vars.to.remove <- c("exposure_id", "pet_gender", "pet_de_sexed_age", "pet_is_switcher", "nb_address_type_adj", "nb_suburb", "nb_state", "person_dob", "owner_age_years", "nb_breed_type",
"nb_breed_trait", "nb_breed_name_unique", "nb_breed_name_unique_concat", "exposure_id_1", "earned_units", "Total_Earned", "claim_nb", "Total_claim_amount",
"Total_claim_paid", "severity", "frequency", "is_multi_plan", "quote_time_group", "sa2_code", "nb_postcode")
frequency.model.data <- combined_data[,-which(colnames(combined_data) %in% vars.to.remove)]
frequency.model.data$qi <- as.factor(frequency.model.data$qi)
frequency.model.data <- na.omit(frequency.model.data)
str(frequency.model.data)
#Splitting into test and training
set.seed(2131)
freq_training_val_index <- sample(1:nrow(frequency.model.data), 0.7*nrow(frequency.model.data))
freq_training_val <- frequency.model.data[freq_training_val_index, ]
freq_test <- frequency.model.data[-freq_training_val_index, ]
var_powers <- seq(1.1, 1.9, by = 0.1)
aic_values <- numeric(length(var_powers))
for (i in seq_along(var_powers)) {
model <- glm(claim_freq ~ ., data = freq_training_val,
family = tweedie(var.power = var_powers[i], link.power = 0))
aic_values[i] <- AIC(model)
}
optimal_var_power <- var_powers[which.min(aic_values)]
optimal_var_power
tweedie_freq_model <- glm(claim_freq~., data = freq_training_val, family = tweedie(var.power = 1.1, link = 0))
tweedie_freq_model$aic
tweedie_freq_model$aic
tweedie_freq_model$aic
tweedie_freq_model$aic
seq_along(var_powers)
MSE_values <- numeric(length(var_powers))
for (i in 1:length(var_powers)) {
tweedie_freq_model <- glm(claim_freq~., data = freq_training_val, family = tweedie(var.power = var_powers[i], link = 0))
MSE_values[i] <- mean(tweedie_freq_model$residuals^2)
}
optimal_var_power <- var_powers[which.min(MSE_values)]
optimal_var_power
var_powers <- seq(1.1, 1.9, by = 0.1)
MSE_values <- numeric(length(var_powers))
for (i in 1:length(var_powers)) {
tweedie_freq_model <- glm(claim_freq~., data = freq_training_val, family = tweedie(var.power = var_powers[i], link = 0))
MSE_values[i] <- mean(tweedie_freq_model$residuals^2)
}
optimal_var_power <- var_powers[which.min(MSE_values)]
var_powers <- seq(1.1, 1.9, by = 0.1)
MSE_values <- numeric(length(var_powers))
for (i in 1:length(var_powers)) {
tweedie_model <- glm(claim_freq~., data = freq_training_val, family = tweedie(var.power = var_powers[i], link = 0))
MSE_values[i] <- mean(tweedie_model$residuals^2)
}
optimal_var_power <- var_powers[which.min(MSE_values)]
tweedie_final_freq <- glm(claim_freq~., data = freq_training_val, family = tweedie(var.power = optimal_var_power, link = 0))
tweedie_final_training_MSE <- min(MSE_values)
tweedie_final_training_MSE
var_powers <- seq(1.1, 1.9, by = 0.1)
MSE_values <- numeric(length(var_powers))
for (i in 1:length(var_powers)) {
tweedie_model <- glm(claim_freq~., data = freq_training_val, family = tweedie(var.power = var_powers[i], link = 0))
MSE_values[i] <- mean(tweedie_model$residuals^2)
}
optimal_var_power <- var_powers[which.min(MSE_values)]
tweedie_final_freq <- glm(claim_freq~., data = freq_training_val, family = tweedie(var.power = optimal_var_power, link = 0))
tweedie_final_training_MSE <- min(MSE_values)
tweedie_final_training_MSE
var_powers <- seq(1.1, 1.9, by = 0.1)
# Prepare a placeholder for MSE results
mse_results <- numeric(length(var_powers))
# Set up cross-validation parameters
train_control <- trainControl(method = "cv", number = 5) # 5-fold CV
# Loop over each candidate var.power
for (i in seq_along(var_powers)) {
current_power <- var_powers[i]
# Train a Tweedie GLM with the current var.power
model <- train(
claim_freq ~ ., data = freq_training_val,  # Replace with your actual data
method = "glm",
family = tweedie(var.power = current_power, link = "log"),
trControl = train_control,
metric = "RMSE"  # Root MSE will be minimized
)
# Store the mean MSE of the cross-validated model
mse_results[i] <- mean(model$resample$RMSE^2)
}
# Identify the var.power with the lowest MSE
optimal_var_power <- var_powers[which.min(mse_results)]
optimal_var_power
which.min(mse_results)
min(mse_results)
final_tweedie_freq <- glm(claim_freq ~., data = freq_training_val, family = tweedie(var.power = optimal_var_power, link.power = 0))
mean(final_tweedie_freq$residuals^2)
sqrt(mean(final_tweedie_freq$residuals^2))
tweedie_freq_model <- glm(claim_freq ~ ., data = freq_training_val, family = tweedie(var.power = optimal_var_power, link = "log"))
mean(tweedie_freq_model$residuals^2)
tweedie_freq_model_training_predictions <- predict(tweedie_freq_model,  data = freq_training_val, type = "response")
tweedie_freq_model_training_predictions
tweedie_freq_model_training_predictions <- as.vector(tweedie_freq_model_training_predictions)
mean((tweedie_freq_model_training_predictions-freq_training_val$claim_freq)^2)
AIC(tweedie_freq_model)
tweedie_freq_model$aic
log_likelihood <- logLik(final_model) # This gives you the log-likelihood
log_likelihood <- logLik(tweedie_freq_model) # This gives you the log-likelihood
# Calculate the number of parameters (including intercept)
k <- length(coef(tweedie_freq_model))
# Calculate AIC manually
aic_manual <- 2 * k - 2 * log_likelihood
# Output the AIC value
aic_manual
coef(tweedie_freq_model)
training_MSE
training_MSE <- mean((tweedie_freq_model_training_predictions-freq_training_val$claim_freq)^2)
training_MSE
summary(tweedie_freq_model)
tweedie_freq_model_prediction <- predict(tweedie_freq_model,  data = test.set, type = "response")
tweedie_freq_model_prediction <- as.vector(tweedie_freq_model_prediction)
tweedie_freq_model_prediction
training_MSE_tweedie <- mean((tweedie_freq_model_training_predictions-freq_training_val$claim_freq)^2)
test_MSE_tweedie <- mean((tweedie_freq_model_prediction-test.set$claim_freq)^2)
test_MSE_tweedie <- mean((tweedie_freq_model_prediction-freq_test$claim_freq)^2)
tweedie_freq_model_prediction <- predict(tweedie_freq_model,  data = freq_test, type = "response")
tweedie_freq_model_prediction <- as.vector(tweedie_freq_model_prediction)
test_MSE_tweedie <- mean((tweedie_freq_model_prediction-freq_test$claim_freq)^2)
tweedie_freq_model_training_predictions <- predict(tweedie_freq_model,  newdata = freq_training_val, type = "response")
tweedie_freq_model_training_predictions <- as.vector(tweedie_freq_model_training_predictions)
training_MSE_tweedie <- mean((tweedie_freq_model_training_predictions-freq_training_val$claim_freq)^2)
tweedie_freq_model_prediction <- predict(tweedie_freq_model,  newdata = freq_test, type = "response")
tweedie_freq_model_prediction <- as.vector(tweedie_freq_model_prediction)
test_MSE_tweedie <- mean((tweedie_freq_model_prediction-freq_test$claim_freq)^2)
test_MSE_tweedie
full_freq_LR_training_MSE
training_MSE_tweedie
training_MSE_tweedie
elastic_test_mse
ridge_test_mse
lasso_test_mse
stepwise_freq_model_test_MSE
freq_rf_test_mse
summary_of_freq_models <- data.frame(Model = c("Full LR", "Elastic Net", "Ridge", "Lasso", "Stepwise", "Random Forest"),
test_MSE = C(training_MSE_tweedie, elastic_test_mse, ridge_test_mse, lasso_test_mse,
stepwise_freq_model_test_MSE, freq_rf_test_mse))
Summary_of_freq_models <- data.frame(
Model = c("Full LR", "Elastic Net", "Ridge", "Lasso", "Stepwise", "Random Forest"),
test_MSE = c(training_MSE_tweedie, elastic_test_mse, ridge_test_mse, lasso_test_mse,
stepwise_freq_model_test_MSE, freq_rf_test_mse)
Summary_of_freq_models <- data.frame(
Summary_of_freq_models <- data.frame(
Model = c("Full LR", "Elastic Net", "Ridge", "Lasso", "Stepwise", "Random Forest"),
test_MSE = c(training_MSE_tweedie, elastic_test_mse, ridge_test_mse, lasso_test_mse,
stepwise_freq_model_test_MSE, freq_rf_test_mse))
Summary_of_freq_models
Summary_of_freq_models <- data.frame(
Model = c("Tweedie", "Full LR", "Elastic Net", "Ridge", "Lasso", "Stepwise", "Random Forest"),
test_MSE = c(training_MSE_tweedie, elastic_test_mse, ridge_test_mse, lasso_test_mse,
stepwise_freq_model_test_MSE, freq_rf_test_mse))
training_MSE_tweedie
elastic_test_mse
ridge_test_mse
lasso_test_mse
stepwise_freq_model_test_MSE
freq_rf_test_mse
training_mse_rf
freq_rf$mse
min(freq_rf$mse)
full_freq_LR_training_MSE
predictions <- predict(full_frequency_LR, newdata = freq_training_val)
full_freq_LR_training_MSE <- mean((freq_training_val$claim_freq - predictions)^2)
full_freq_LR_training_MSE <- mean(full_frequency_LR$residuals^2)
full_freq_LR_training_MSE
stepwise_model_freq_summary$adj.r.squared
predictions_stepwise <- predict(stepwise_model_freq, newdata = freq_training_val)
stepwise_model_freq_training_MSE <- mean((freq_training_val$claim_freq - predictions_stepwise)^2)
stepwise_model_freq_training_MSE
lasso_freq_predictions <- predict(final_freq_lasso_model, newx =model.matrix(claim_freq~., data = freq_test), type = "response")
lasso_freq_predictions <- as.vector(lasso_freq_predictions)
lasso_freq_predictions
mean((lasso_freq_predictions-freq_test$claim_freq)^2)
lasso_freq_predictions_training <- predict(final_freq_lasso_model, newx = X.training, type = "response")
lasso_freq_predictions_training <- as.vector(lasso_freq_predictions_training)
Lasso_mean((lasso_freq_predictions_training-freq_test$claim_freq)^2)
mean((lasso_freq_predictions_training-freq_test$claim_freq)^2)
mean((lasso_freq_predictions_training-Y.training)^2)
training_lasso_MSE <- mean((lasso_freq_predictions_training-Y.training)^2)
ridge_freq_predictions_training <- predict(final_ridge_model_freq, newx = X.training, type = "response")
ridge_freq_predictions_training <- as.vector(ridge_freq_predictions_training)
training_lasso_MSE <- mean((ridge_freq_predictions_training-Y.training)^2)
training_lasso_MSE
elastic_training_MSE <- mean((final_elastic_net_model_training_predictions-Y.training)^2)
final_elastic_net_model_training_predictions <- predict(final_elastic_net_model, newx = X.training, type = "response")
final_elastic_net_model_training_predictions <- as.vector(final_elastic_net_model_training_predictions)
elastic_training_MSE <- mean((final_elastic_net_model_training_predictions-Y.training)^2)
elastic_training_MSE
ridge_freq_predictions_training <- predict(final_ridge_model_freq, newx = X.training, type = "response")
ridge_freq_predictions_training <- as.vector(ridge_freq_predictions_training)
training_ridge_MSE <- mean((ridge_freq_predictions_training-Y.training)^2)
full_freq_LR_training_MSE <- mean((freq_training_val$claim_freq - predictions)^2)
training_MSEs <- c(
training_MSE_tweedie,
elastic_training_MSE,
training_ridge_MSE,
training_lasso_MSE,
full_freq_LR_training_MSE,
stepwise_model_freq_training_MSE,
training_mse_rf
)
test_MSEs <- c(
elastic_test_mse,
ridge_test_mse,
lasso_test_mse,
full_freq_test_MSE,
stepwise_freq_model_test_MSE,
freq_rf_test_mse
)
# Define the model types
model_types <- c(
"Tweedie",
"Elastic Net",
"Ridge",
"Lasso",
"Full Linear Regression",
"Stepwise Regression",
"Random Forest"
)
# Create a data frame for training MSE
training_df <- data.frame(
Model = model_types,
Training_MSE = training_MSEs
)
# Create a data frame for test MSE (adjust the model types as necessary)
test_df <- data.frame(
Model = model_types[-length(model_types)],  # Exclude one model for test MSE
Test_MSE = test_MSEs
)
# Combine training and test data frames
combined_df <- merge(training_df, test_df, by = "Model", all = TRUE)
combined_df
>>>>>>> 0dacbe98f43461d89b0702fae8e06718452fd531
