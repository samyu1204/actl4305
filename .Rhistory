combined_data$pet_age_year <- combined_data$pet_age_months / 12
# Convert breed trait into numeric
average_severity_by_trait <- aggregate(severity ~ nb_breed_trait_num, data = combined_data, FUN = mean)
# Order the nb_breed_trait_num levels based on the average severity
average_severity_by_trait <- average_severity_by_trait[order(average_severity_by_trait$severity), ]
# Create encoding for test data
average_severity_by_trait$nb_breed_trait_num_encoded <- seq_len(nrow(average_severity_by_trait))
# # Assign numeric encoding based on the ordered severity
# combined_data$nb_breed_trait_num_encoded <- factor(
#   combined_data$nb_breed_trait_num,
#   levels = average_severity_by_trait$nb_breed_trait_num,   # Ordering the levels based on severity
#   ordered = TRUE                                           # Ensuring it's treated as an ordered factor
# )
combined_data <- merge(combined_data, average_severity_by_trait[, c("nb_breed_trait_num", "nb_breed_trait_num_encoded")],
by = "nb_breed_trait_num", all.x = TRUE)
# Order the factors into numerical
combined_data$nb_breed_trait_num_encoded <- as.numeric(combined_data$nb_breed_trait_num_encoded)
ggplot(combined_data, aes(x = nb_breed_trait_num_encoded, y = severity)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Average Severity by breed trait",
x = "Breed Trait Group",
y = "Average Severity") +
theme_minimal()
# =========================================================================================
# Postcode features
summarized_data <- combined_data %>%
group_by(qi) %>%
summarize(avg_severity = mean(severity, na.rm = TRUE))
ggplot(summarized_data, aes(x = qi, y = avg_severity)) +
geom_col(fill = "steelblue") +
labs(title = "Average Severity by QI Level",
x = "QI Level",
y = "Average Severity") +
theme_minimal()
# ========================================================================================
# Visualizing the relationship between binned Age * Breed Size and frequency
library(readr)
sample <- read_csv("data/New_Customers_Pricing_Output_File.csv")
start_cols <- colnames(sample)
# ===============================================================================
# ==============================================================================
# Feature engineering
# Numerical variable conversion
sample$pet_is_male <- ifelse(sample$pet_gender == 'male', 1, 0)
# Convert complex type into numerical encoding
sample$nb_address_type_adj <- as.factor(sample$nb_address_type_adj)
sample$nb_address_type_adj_numerical <- as.numeric(sample$nb_address_type_adj)
# Convert state
sample$nb_state <- as.factor(sample$nb_state)
sample$nb_state_num <- as.numeric(sample$nb_state)
# Convert breed type
sample$nb_breed_type <- as.factor(sample$nb_breed_type)
sample$nb_breed_type_num <- as.numeric(sample$nb_breed_type)
# Convert pet desexed
sample$pet_de_sexed <- as.factor(sample$pet_de_sexed)
sample$nb_breed_type_num <- as.numeric(sample$nb_breed_type)
# Convert breed trait
sample$nb_breed_trait <- as.factor(sample$nb_breed_trait)
sample$nb_breed_trait_num <- as.numeric(sample$nb_breed_trait)
# Multi-pet plan
sample$is_multi_pet_plan <- as.factor(sample$is_multi_pet_plan)
sample$is_multi_pet_plan_num <- as.numeric(sample$is_multi_pet_plan)
# Quote average time
sample$quote_time_group <- as.factor(sample$quote_time_group)
sample$quote_time_group_num <- as.numeric(sample$quote_time_group)
# Breed size encoding
sample <- sample %>%
mutate(size_encoding = ifelse(nb_average_breed_size %in% c(1, 2, 3), 1, 0))
sample$size_encoding
# Owner age * pet age
sample$owner_x_pet_age <- sample$owner_age_years * sample$pet_age_months / 12
sample$owner_x_pet_age <- cut(sample$owner_x_pet_age,
breaks = c(seq(0, 700, by = 15), Inf),
labels = as.character(1:(length(seq(0, 700, by = 15)))))
sample$owner_x_pet_age <- pmin(as.numeric(sample$owner_x_pet_age), 10)
sample$owner_age_years
# Breed interactions
sample$age_breed_interaction <- sample$pet_age_months * sample$nb_average_breed_size
sample$age_breed_interaction %>% summary
sample$nb_average_breed_size
sample$age_breed_interaction_bins <- cut(sample$age_breed_interaction,
breaks = c(seq(0, 200, by = 5), Inf),
labels = as.character(1:(length(seq(0, 200, by = 5)))))
sample$age_breed_interaction_bins <- as.numeric(sample$age_breed_interaction_bins)
sample$age_breed_interaction <- pmin(sample$age_breed_interaction, 10)
# Owner's age
current_date <- Sys.Date()
sample$person_age <- floor(interval(as.Date(sample$person_dob), current_date) / years(1))
sample$person_age_group <- cut(
sample$person_age,
breaks = seq(0, 100, by = 20),   # Create intervals from 0 to 100, each of 5 years
right = FALSE,                  # Ensure that the intervals are left-closed (e.g., [0,5), [5,10), etc.)
labels = paste(seq(0, 95, by = 20), seq(5, 100, by = 20), sep = "-")  # Create labels like "0-5", "5-10", etc.
)
sample$person_age_group <- as.numeric(sample$person_age_group)
# Pet age years
sample$pet_age_year <- sample$pet_age_months / 12
# Order the factors into numerical
sample <- merge(sample, average_severity_by_trait[, c("nb_breed_trait_num", "nb_breed_trait_num_encoded")],
by = "nb_breed_trait_num", all.x = TRUE)
sample$nb_breed_trait_num_encoded
# Load necessary libraries
library(stats)
library(dplyr)
library(gamlr)
library(tweedie)
library(mgcv)
library(statmod)
library(forcats)
library(tidyr)
library(randomForest)
library(MASS)
library(glmnet)
library(caret)
library(gbm)
# Set seed for the run
set.seed(123)
# Prepare severity data
severity_data <- combined_data %>% filter(severity > 0)
# Calculate the mean, ignoring NA values
mean_value <- mean(severity_data$owner_age_years, na.rm = TRUE)
severity_data$owner_age_years[is.na(severity_data$owner_age_years)] <- mean_value
mean_value <- mean(severity_data$density, na.rm = TRUE)
severity_data$density[is.na(severity_data$density)] <- mean_value
# Feature list
features <- c(
'nb_breed_trait_num_encoded',
'pet_age_months',
'nb_excess',
'owner_age_years',
'density',
'age_breed_interaction'
)
# Join the features to form a formula with underscores between feature names
formula <- as.formula(paste("severity", "~", paste(features, collapse = " + "), sep = ""))
# Fit the GLM model
glm_model <- glm(formula, family = Gamma(link = "log"), data = severity_data)
# Summary
summary(glm_model)
# Fit the GLM model
glm_model_severity <- glm(formula, family = Gamma(link = "log"), data = severity_data)
# Calculate residuals from the initial GLM model
severity_data$severity_difference <- severity_data$severity - predict(glm_model, type = "response")
# Define the formula
formula <- as.formula(paste("severity_difference", "~", paste(features, collapse = " + "), sep = ""))
# Create a weight vector based on severity values (example: higher weights for top 25% of severity values)
severity_data$weights <- ifelse(severity_data$severity > quantile(severity_data$severity, 0.75), 1.5, 1)
# Define the hyperparameter grid
hyper_grid <- expand.grid(
n.trees = c(500, 1000, 1500, 2000, 2500, 3000),
interaction.depth = c(2),
shrinkage = c(0.01),
n.minobsinnode = c(10, 20, 30)
)
# Set up cross-validation
train_control <- trainControl(method = "cv", number = 5, verboseIter = FALSE)
# Train the GBM model using caret with cross-validation and weights
gbm_tuned <- train(
formula,
data = severity_data,
method = "gbm",
distribution = "gaussian",
trControl = train_control,
tuneGrid = hyper_grid,
weights = severity_data$weights,
verbose = FALSE
)
# Train the GBM model using caret with cross-validation and weights
gbm_tuned_severity <- train(
formula,
data = severity_data,
method = "gbm",
distribution = "gaussian",
trControl = train_control,
tuneGrid = hyper_grid,
weights = severity_data$weights,
verbose = FALSE
)
start_cols
# ===============================================================================
# Predict severity
sample$pred_severity <- predict(glm_model_severity, type = "response")
# ===============================================================================
# Predict severity
sample$pred_severity <- predict(glm_model_severity, newdata = sample, type = "response")
# =========
# Merge SA2 code onto it
sa2_mapping <- read_excel("data/sa2_mapping.xlsx")
sa2_mapping$nb_postcode <- as.character(sa2_mapping$nb_postcode)
sa2_mapping <- sa2_mapping %>%
dplyr::group_by(nb_postcode) %>%
dplyr::slice(1)
sa2_mapping_selected <- sa2_mapping %>%
dplyr::select(nb_postcode, SA2_CODE)
# Perform the left join to get SA2 Code
sample <- left_join(sample, sa2_mapping_selected, by = "nb_postcode")
sample$nb_postcode <- as.character(sample$nb_postcode)
sa2_mapping$nb_postcode <- as.character(sa2_mapping$nb_postcode)
sa2_mapping <- sa2_mapping %>%
dplyr::group_by(nb_postcode) %>%
dplyr::slice(1)
sa2_mapping_selected <- sa2_mapping %>%
dplyr::select(nb_postcode, SA2_CODE)
# Perform the left join to get SA2 Code
sample <- left_join(sample, sa2_mapping_selected, by = "nb_postcode")
names(combined_data)[names(combined_data) == "SA2_CODE"] <- "sa2_code"
# =========
# Merge SA2 code onto it
sa2_mapping <- read_excel("data/sa2_mapping.xlsx")
sample$nb_postcode <- as.character(sample$nb_postcode)
sa2_mapping$nb_postcode <- as.character(sa2_mapping$nb_postcode)
sa2_mapping <- sa2_mapping %>%
dplyr::group_by(nb_postcode) %>%
dplyr::slice(1)
sa2_mapping_selected <- sa2_mapping %>%
dplyr::select(nb_postcode, SA2_CODE)
# Perform the left join to get SA2 Code
sample <- left_join(sample, sa2_mapping_selected, by = "nb_postcode")
names(sample)[names(sample) == "SA2_CODE"] <- "sa2_code"
sample$sa2_code <- as.character(sample$sa2_code)
# Merge SA2 code onto it
sa2_mapping <- read_excel("data/sa2_mapping.xlsx")
sample$nb_postcode <- as.character(sample$nb_postcode)
sa2_mapping$nb_postcode <- as.character(sa2_mapping$nb_postcode)
sa2_mapping <- sa2_mapping %>%
dplyr::group_by(nb_postcode) %>%
dplyr::slice(1)
sa2_mapping_selected <- sa2_mapping %>%
dplyr::select(nb_postcode, SA2_CODE)
# Perform the left join to get SA2 Code
sample <- left_join(sample, sa2_mapping_selected, by = "nb_postcode")
View(sample)
# Perform the left join to get SA2 Code
sample <- left_join(sample, sa2_mapping_selected, by = "nb_postcode")
names(sample)[names(sample) == "SA2_CODE"] <- "sa2_code"
sample$sa2_code <- as.character(sample$sa2_code)
sample$sa2_code
# Merge SA2 code onto it
sa2_mapping <- read_excel("data/sa2_mapping.xlsx")
sample$nb_postcode <- as.character(sample$nb_postcode)
sa2_mapping$nb_postcode <- as.character(sa2_mapping$nb_postcode)
sa2_mapping <- sa2_mapping %>%
dplyr::group_by(nb_postcode) %>%
dplyr::slice(1)
sa2_mapping_selected <- sa2_mapping %>%
dplyr::select(nb_postcode, SA2_CODE)
# Perform the left join to get SA2 Code
sample <- left_join(sample, sa2_mapping_selected, by = "nb_postcode")
sample$SA2_CODE
names(sample)[names(sample) == "SA2_CODE"] <- "sa2_code"
sample$SA2_CODE
sample$sa2_code
sample$sa2_code
sample$sa2_code <- as.character(sample$sa2_code)
sample$sa2_code
names(sample)[names(sample) == "SA2_CODE"] <- "sa2_code"
sample$sa2_code <- as.character(sample$sa2_code)
# QI quality indicator of the postcode
qi <- read_excel("data/QI.xlsx")
qi <- qi %>%
dplyr::group_by(sa2_code) %>%
dplyr::slice(1)
# Join onto
sample <- left_join(sample, qi, by = "sa2_code")
# Join pop density
sa2_pop_density <- read_excel("data/sa2_pop_density.xlsx")
sa2_pop_density$sa2_code <- as.character(sa2_pop_density$sa2_code)
sample <- left_join(sample, sa2_pop_density, by = "sa2_code")
View(sample)
# ===============================================================================
# Predict severity
sample$pred_severity <- predict(glm_model_severity, newdata = sample, type = "response")
sample$pred_severity
sample$pred_severity %>% summary
sample$pred_severity[is.na(sample$pred_severity)] <- 212
sample$pred_severity %>% summary
# Predict frequency
sample$severity_gbm <- ifelse(
sample$pred_severity > 1000,
predict(gbm_tuned, newdata = severity_data),
0  # Set to 0 if severity is <= 1000
)
# Predict frequency
sample$severity_gbm <- ifelse(
sample$pred_severity > 1000,
predict(gbm_tuned_severity, newdata = severity_data),
0  # Set to 0 if severity is <= 1000
)
sample$severity_gbm
# ===============================================================================
# Predict severity
sample$pred_severity <- predict(glm_model_severity, newdata = sample, type = "response")
sample$pred_severity %>% summary
# Predict frequency
sample$severity_gbm <- ifelse(
sample$pred_severity > 1000,
predict(gbm_tuned_severity, newdata = severity_data),
0  # Set to 0 if severity is <= 1000
)
sample$pred_severity %>% summary
sample$pred_severity_final <- sample$pred_severity + sample$severity_gbm
sample$pred_severity %>% summary
sample$pred_severity_final %>% summary
sample$pred_severity_final[is.na(sample$pred_severity)] <- 212
sample$pred_severity_final %>% summary
# ==================================================================================================
# GLM - Tweedie
# ==================================================================================================
var_powers <- seq(1.1, 1.9, by = 0.1)
mse_results <- numeric(length(var_powers))
train_control <- trainControl(method = "cv", number = 5)
for (i in seq_along(var_powers)) {
current_power <- var_powers[i]
model <- train(
claim_freq ~ ., data = freq_training_val,
method = "glm",
family = tweedie(var.power = current_power, link = "log"),
trControl = train_control,
metric = "RMSE"
)
mse_results[i] <- mean(model$resample$RMSE^2)
}
# Final predictions after combining GLM and GBM
severity_data$final_pred_severity <- severity_data$pred_glm + severity_data$pred_gbm_diff
vars.to.remove <- c("exposure_id", "pet_gender", "pet_de_sexed_age", "pet_is_switcher", "nb_address_type_adj", "nb_suburb", "nb_state", "person_dob", "owner_age_years", "nb_breed_type",
"nb_breed_trait", "nb_breed_name_unique", "nb_breed_name_unique_concat", "exposure_id_1", "earned_units", "Total_Earned", "claim_nb", "Total_claim_amount",
"Total_claim_paid", "severity", "frequency", "is_multi_plan", "quote_time_group", "sa2_code", "nb_postcode")
frequency.model.data <- combined_data[,-which(colnames(combined_data) %in% vars.to.remove)]
frequency.model.data$qi <- as.factor(frequency.model.data$qi)
frequency.model.data <- na.omit(frequency.model.data)
str(frequency.model.data)
set.seed(2131)
freq_training_val_index <- sample(1:nrow(frequency.model.data), 0.7*nrow(frequency.model.data))
set.seed(2131)
freq_training_val_index <- sample(1:nrow(frequency.model.data), 0.7*nrow(frequency.model.data))
freq_training_val <- frequency.model.data[freq_training_val_index, ]
freq_test <- frequency.model.data[-freq_training_val_index, ]
######random forest model
freq_rf <- randomForest(claim_freq ~., data = freq_training_val, ntree = 100, importance = TRUE)
# ==================================================================================================
# GLM - Tweedie
# ==================================================================================================
var_powers <- seq(1.1, 1.9, by = 0.1)
mse_results <- numeric(length(var_powers))
train_control <- trainControl(method = "cv", number = 5)
for (i in seq_along(var_powers)) {
current_power <- var_powers[i]
model <- train(
claim_freq ~ ., data = freq_training_val,
method = "glm",
family = tweedie(var.power = current_power, link = "log"),
trControl = train_control,
metric = "RMSE"
)
mse_results[i] <- mean(model$resample$RMSE^2)
}
optimal_var_power <- var_powers[which.min(mse_results)]
optimal_var_power
tweedie_freq_model <- glm(claim_freq ~ ., data = freq_training_val, family = tweedie(var.power = optimal_var_power, link = "log"))
summary(tweedie_freq_model)
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
combined_data$UW_Date
sample <- as.Date(sample$quote_date)
sample <- as.Date(sample$quote_date)
sample$UW_Date <- as.Date(sample$quote_date)
sample
library(readr)
sample <- read_csv("data/New_Customers_Pricing_Output_File.csv")
start_cols <- colnames(sample)
# ===============================================================================
# ==============================================================================
# Feature engineering
# Numerical variable conversion
sample$pet_is_male <- ifelse(sample$pet_gender == 'male', 1, 0)
# Convert complex type into numerical encoding
sample$nb_address_type_adj <- as.factor(sample$nb_address_type_adj)
sample$nb_address_type_adj_numerical <- as.numeric(sample$nb_address_type_adj)
# Convert state
sample$nb_state <- as.factor(sample$nb_state)
sample$nb_state_num <- as.numeric(sample$nb_state)
# Convert breed type
sample$nb_breed_type <- as.factor(sample$nb_breed_type)
sample$nb_breed_type_num <- as.numeric(sample$nb_breed_type)
# Convert pet desexed
sample$pet_de_sexed <- as.factor(sample$pet_de_sexed)
sample$nb_breed_type_num <- as.numeric(sample$nb_breed_type)
# Convert breed trait
sample$nb_breed_trait <- as.factor(sample$nb_breed_trait)
sample$nb_breed_trait_num <- as.numeric(sample$nb_breed_trait)
# Multi-pet plan
sample$is_multi_pet_plan <- as.factor(sample$is_multi_pet_plan)
sample$is_multi_pet_plan_num <- as.numeric(sample$is_multi_pet_plan)
# Quote average time
sample$quote_time_group <- as.factor(sample$quote_time_group)
sample$quote_time_group_num <- as.numeric(sample$quote_time_group)
# Breed size encoding
sample <- sample %>%
mutate(size_encoding = ifelse(nb_average_breed_size %in% c(1, 2, 3), 1, 0))
sample$size_encoding
# Owner age * pet age
sample$owner_x_pet_age <- sample$owner_age_years * sample$pet_age_months / 12
sample$owner_x_pet_age <- cut(sample$owner_x_pet_age,
breaks = c(seq(0, 700, by = 15), Inf),
labels = as.character(1:(length(seq(0, 700, by = 15)))))
sample$owner_x_pet_age <- pmin(as.numeric(sample$owner_x_pet_age), 10)
sample$owner_age_years
# Breed interactions
sample$age_breed_interaction <- sample$pet_age_months * sample$nb_average_breed_size
sample$age_breed_interaction %>% summary
sample$nb_average_breed_size
sample$age_breed_interaction_bins <- cut(sample$age_breed_interaction,
breaks = c(seq(0, 200, by = 5), Inf),
labels = as.character(1:(length(seq(0, 200, by = 5)))))
sample$age_breed_interaction_bins <- as.numeric(sample$age_breed_interaction_bins)
sample$age_breed_interaction <- pmin(sample$age_breed_interaction, 10)
# Owner's age
current_date <- Sys.Date()
sample$person_age <- floor(interval(as.Date(sample$person_dob), current_date) / years(1))
sample$person_age_group <- cut(
sample$person_age,
breaks = seq(0, 100, by = 20),   # Create intervals from 0 to 100, each of 5 years
right = FALSE,                  # Ensure that the intervals are left-closed (e.g., [0,5), [5,10), etc.)
labels = paste(seq(0, 95, by = 20), seq(5, 100, by = 20), sep = "-")  # Create labels like "0-5", "5-10", etc.
)
sample$person_age_group <- as.numeric(sample$person_age_group)
# Pet age years
sample$pet_age_year <- sample$pet_age_months / 12
# Order the factors into numerical
sample <- merge(sample, average_severity_by_trait[, c("nb_breed_trait_num", "nb_breed_trait_num_encoded")],
by = "nb_breed_trait_num", all.x = TRUE)
# =========
# Merge SA2 code onto it
sa2_mapping <- read_excel("data/sa2_mapping.xlsx")
sample$nb_postcode <- as.character(sample$nb_postcode)
sa2_mapping$nb_postcode <- as.character(sa2_mapping$nb_postcode)
sa2_mapping <- sa2_mapping %>%
dplyr::group_by(nb_postcode) %>%
dplyr::slice(1)
sa2_mapping_selected <- sa2_mapping %>%
dplyr::select(nb_postcode, SA2_CODE)
# Perform the left join to get SA2 Code
sample <- left_join(sample, sa2_mapping_selected, by = "nb_postcode")
sample$sa2_code
names(sample)[names(sample) == "SA2_CODE"] <- "sa2_code"
sample$sa2_code <- as.character(sample$sa2_code)
# QI quality indicator of the postcode
qi <- read_excel("data/QI.xlsx")
qi <- qi %>%
dplyr::group_by(sa2_code) %>%
dplyr::slice(1)
# Join onto
sample <- left_join(sample, qi, by = "sa2_code")
# Join pop density
sa2_pop_density <- read_excel("data/sa2_pop_density.xlsx")
sa2_pop_density$sa2_code <- as.character(sa2_pop_density$sa2_code)
sample <- left_join(sample, sa2_pop_density, by = "sa2_code")
sample$UW_Date <- as.Date(sample$quote_date)
sample
sample$UW_Date
# ===============================================================================
# Predict severity
sample$pred_severity <- predict(glm_model_severity, newdata = sample, type = "response")
sample$pred_severity %>% summary
# Predict frequency
sample$severity_gbm <- ifelse(
sample$pred_severity > 1000,
predict(gbm_tuned_severity, newdata = severity_data),
0  # Set to 0 if severity is <= 1000
)
sample$pred_severity_final <- sample$pred_severity + sample$severity_gbm
sample$pred_severity_final %>% summary
sample$pred_severity_final[is.na(sample$pred_severity)] <- 212
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
sample$tenure <- 1
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
sample$nb_policy_first_inception_date <- as.Date(sample$quote_date)
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
sample$nb_breed_trait_num_encoded
sample$nb_breed_trait_num_encoded.x <- sample$nb_breed_trait_num_encoded
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
sample$nb_breed_trait_num_encoded.y <- sample$nb_breed_trait_num_encoded
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
sample$pet_de_sexed
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
freq_training_val$pet_de_sexed
sample$pet_de_sexed <- tolower(sample$pet_de_sexed)
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
sample$is_multi_pet_plan <- tolower(sample$is_multi_pet_plan)
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
sample$nb_breed_trait_num_encoded.y <- as.factor(sample$nb_breed_trait_num_encoded)
sample$nb_breed_trait_num_encoded.x <- as.factor(sample$nb_breed_trait_num_encoded)
sample$nb_breed_trait_num_encoded.y <- as.factor(sample$nb_breed_trait_num_encoded)
sample$pet_de_sexed <- tolower(sample$pet_de_sexed)
sample$is_multi_pet_plan <- tolower(sample$is_multi_pet_plan)
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
sample$nb_breed_trait_num_encoded.x <- factor(
sample$nb_breed_trait_num_encoded.x,
levels = levels(combined_data$nb_breed_trait_num_encoded.x)  # Match levels to training data
)
# Predict frequency with glm
sample$pred_freq <- predict(tweedie_freq_model, newdata = sample, type = "response")
